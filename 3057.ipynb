{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T04:16:53.195791Z",
     "iopub.status.busy": "2026-01-02T04:16:53.195526Z",
     "iopub.status.idle": "2026-01-02T04:16:57.367760Z",
     "shell.execute_reply": "2026-01-02T04:16:57.367015Z",
     "shell.execute_reply.started": "2026-01-02T04:16:53.195769Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.69 s, sys: 669 ms, total: 4.36 s\n",
      "Wall time: 4.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "from datetime import datetime\n",
    "import gc\n",
    "import pickle as pkl\n",
    "import shelve\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cudf\n",
    "\n",
    "sys.path.append(\"../input/\")\n",
    "from handmhelpers1 import io as h_io, sub as h_sub, cv as h_cv, fe as h_fe\n",
    "from handmhelpers1 import modeling as h_modeling, candidates as h_can, pairs as h_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and convert data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T04:16:57.369172Z",
     "iopub.status.busy": "2026-01-02T04:16:57.368847Z",
     "iopub.status.idle": "2026-01-02T04:16:57.374647Z",
     "shell.execute_reply": "2026-01-02T04:16:57.373980Z",
     "shell.execute_reply.started": "2026-01-02T04:16:57.369146Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import cudf\n",
    "import numpy as np\n",
    "\n",
    "def patched_day_week_numbers(dates: cudf.Series):\n",
    "    pd_dates = cudf.to_datetime(dates)\n",
    "    unique_dates = cudf.Series(pd_dates.unique())\n",
    "    numbered_days = unique_dates - unique_dates.min() + timedelta(1)\n",
    "    numbered_days = numbered_days.dt.days\n",
    "    extra_days = numbered_days.max() % 7\n",
    "    numbered_days -= extra_days\n",
    "    day_weeks = (numbered_days + 6) // 7  # không dùng applymap\n",
    "    day_weeks_map = cudf.DataFrame({\"day_weeks\": day_weeks, \"unique_dates\": unique_dates}).set_index(\"unique_dates\")[\"day_weeks\"]\n",
    "    all_day_weeks = pd_dates.map(day_weeks_map).astype(\"int8\")\n",
    "    return all_day_weeks\n",
    "\n",
    "import handmhelpers1.fe as h_fe\n",
    "h_fe.day_week_numbers = patched_day_week_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T04:16:57.376549Z",
     "iopub.status.busy": "2026-01-02T04:16:57.376334Z",
     "iopub.status.idle": "2026-01-02T04:17:01.210955Z",
     "shell.execute_reply": "2026-01-02T04:17:01.210097Z",
     "shell.execute_reply.started": "2026-01-02T04:16:57.376530Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.08 s, sys: 1.74 s, total: 4.82 s\n",
      "Wall time: 3.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "c, t, a = h_io.load_data(files=['customers.csv', 'transactions_train.csv', 'articles.csv'])        \n",
    "\n",
    "index_to_id_dict_path = h_fe.reduce_customer_id_memory(c, [t])\n",
    "t[\"week_number\"] = h_fe.day_week_numbers(t[\"t_dat\"])\n",
    "t[\"t_dat\"] = h_fe.day_numbers(t[\"t_dat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get item pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T04:17:01.212269Z",
     "iopub.status.busy": "2026-01-02T04:17:01.211993Z",
     "iopub.status.idle": "2026-01-02T04:17:39.396424Z",
     "shell.execute_reply": "2026-01-02T04:17:39.395679Z",
     "shell.execute_reply.started": "2026-01-02T04:17:01.212245Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating pairs for week number 94\n",
      "Creating pairs for week number 95\n",
      "Creating pairs for week number 96\n",
      "Creating pairs for week number 97\n",
      "Creating pairs for week number 98\n",
      "Creating pairs for week number 99\n",
      "Creating pairs for week number 100\n",
      "Creating pairs for week number 101\n",
      "Creating pairs for week number 102\n",
      "Creating pairs for week number 103\n",
      "Creating pairs for week number 104\n",
      "CPU times: user 29.6 s, sys: 8.49 s, total: 38.1 s\n",
      "Wall time: 38.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Tạo cặp bài viết cho nhiều tuần lịch sử (94–104) với 15 cặp mỗi bài để nâng recall ứng viên\n",
    "pairs_per_item = 15\n",
    "\n",
    "week_number_pairs = {}\n",
    "for week_number in [94,95,96, 97, 98, 99, 100, 101, 102, 103, 104]:\n",
    "    print(f\"Creating pairs for week number {week_number}\")\n",
    "    week_number_pairs[week_number] = h_pairs.create_pairs(\n",
    "        t, week_number, pairs_per_item, verbose=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main retrieval/features function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T04:17:39.397714Z",
     "iopub.status.busy": "2026-01-02T04:17:39.397463Z",
     "iopub.status.idle": "2026-01-02T04:17:39.419020Z",
     "shell.execute_reply": "2026-01-02T04:17:39.418274Z",
     "shell.execute_reply.started": "2026-01-02T04:17:39.397690Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_candidates_with_features_df(t, c, a, customer_batch=None, **kwargs):\n",
    "    # Tách dữ liệu theo tuần label: features dùng các tuần trước, label là tuần đích\n",
    "    features_df, label_df = h_cv.feature_label_split(\n",
    "        t, kwargs[\"label_week\"], kwargs[\"feature_periods\"]\n",
    "    )\n",
    "    # Chuẩn hóa thời gian về “cách đây bao nhiêu ngày/tuần”\n",
    "    features_df[\"t_dat\"] = h_fe.how_many_ago(features_df[\"t_dat\"])\n",
    "    features_df[\"week_number\"] = h_fe.how_many_ago(features_df[\"week_number\"])\n",
    "\n",
    "    article_pairs_df = week_number_pairs[kwargs[\"label_week\"] - 1]\n",
    "\n",
    "    # Xác định tập khách hàng cần xử lý (full/batch/label)\n",
    "    if len(label_df) > 0:\n",
    "        customers = label_df[\"customer_id\"].unique()\n",
    "    elif customer_batch is not None:\n",
    "        customers = customer_batch\n",
    "    else:\n",
    "        customers = None\n",
    "\n",
    "    # ----- Ứng viên từ nhiều nguồn và đặc trưng rule -----\n",
    "    features_db = {}\n",
    "    recent_customer_cand, features_db[\"customer_article\"] = h_can.create_recent_customer_candidates(\n",
    "        features_df, kwargs[\"ca_num_weeks\"], customers=customers\n",
    "    )\n",
    "    (\n",
    "        cust_last_week_cand,\n",
    "        cust_last_week_pair_cand,\n",
    "        features_db[\"clw\"],\n",
    "        features_db[\"clw_pairs\"],\n",
    "    ) = h_can.create_last_customer_weeks_and_pairs(\n",
    "        features_df, article_pairs_df, kwargs[\"clw_num_weeks\"], kwargs[\"clw_num_pair_weeks\"], customers=customers\n",
    "    )\n",
    "    popular_can, features_db[\"popular_articles\"] = h_can.create_popular_article_cand(\n",
    "        features_df, c, a, kwargs[\"pa_num_weeks\"], kwargs[\"hier_col\"],\n",
    "        num_candidates=kwargs[\"num_recent_candidates\"],\n",
    "        num_articles=kwargs[\"num_recent_articles\"],\n",
    "        customers=customers,\n",
    "    )\n",
    "    (age_bucket_can, _, age_bucket_pair_features) = h_can.create_age_bucket_candidates(\n",
    "        features_df, c, kwargs[\"num_age_buckets\"], articles=kwargs[\"num_recent_articles\"], customers=customers\n",
    "    )\n",
    "    features_db[\"age_bucket\"] = age_bucket_pair_features\n",
    "\n",
    "    # NEW: ứng viên random walk\n",
    "    random_walk_cand, features_db[\"f_random_walk\"] = h_can.create_random_walk_candidates(\n",
    "        features_df,\n",
    "        article_pairs_df,\n",
    "        seed_weeks=kwargs[\"gd_seed_weeks\"],\n",
    "        seed_articles=kwargs[\"gd_seed_articles\"],\n",
    "        num_steps=kwargs[\"gd_steps\"],\n",
    "        restart_prob=kwargs[\"gd_restart_prob\"],\n",
    "        topk=kwargs[\"gd_topk\"],\n",
    "        weight_col=kwargs[\"gd_weight_col\"],\n",
    "        recency_weight=kwargs[\"gd_recency_weight\"],\n",
    "        exclude_seed_items=kwargs[\"gd_exclude_seed\"],\n",
    "        customers=customers,\n",
    "    )\n",
    "\n",
    "    # Gom rule-score từ từng nguồn\n",
    "    def build_rule_part(cand_df, feature_tuple, score_col, rule_name):\n",
    "        feature_df = feature_tuple[1].reset_index()[[\"customer_id\", \"article_id\", score_col]]\n",
    "        tmp = cand_df.merge(feature_df, on=[\"customer_id\", \"article_id\"], how=\"left\")\n",
    "        tmp = tmp.rename(columns={score_col: \"rule_score\"})\n",
    "        tmp[\"rule_score\"] = tmp[\"rule_score\"].fillna(-1)\n",
    "        tmp[\"rule\"] = rule_name\n",
    "        return tmp[[\"customer_id\", \"article_id\", \"rule\", \"rule_score\"]]\n",
    "\n",
    "    rule_parts = [\n",
    "        build_rule_part(recent_customer_cand, features_db[\"customer_article\"], \"ca_purchase_count\", \"recent\"),\n",
    "        build_rule_part(cust_last_week_cand, features_db[\"clw\"], \"ca_count\", \"last_weeks\"),\n",
    "        build_rule_part(cust_last_week_pair_cand, features_db[\"clw_pairs\"], \"pair_lift\", \"pairs\"),\n",
    "        build_rule_part(age_bucket_can, features_db[\"age_bucket\"], \"article_bucket_count\", \"age_bucket\"),\n",
    "    ]\n",
    "    # rule popular\n",
    "    pop_feature_df = features_db[\"popular_articles\"][1].reset_index()[[\"article_id\", \"recent_popularity_counts\"]]\n",
    "    pop_rule = popular_can.merge(pop_feature_df, on=\"article_id\", how=\"left\")\n",
    "    pop_rule = pop_rule.rename(columns={\"recent_popularity_counts\": \"rule_score\"})\n",
    "    pop_rule[\"rule_score\"] = pop_rule[\"rule_score\"].fillna(-1)\n",
    "    pop_rule[\"rule\"] = \"popular\"\n",
    "    rule_parts.append(pop_rule[[\"customer_id\", \"article_id\", \"rule\", \"rule_score\"]])\n",
    "    # rule random_walk\n",
    "    rule_parts.append(\n",
    "        build_rule_part(random_walk_cand, features_db[\"f_random_walk\"], \"rw_score\", \"random_walk\")\n",
    "    )\n",
    "\n",
    "    rule_df = cudf.concat(rule_parts).sort_values(\n",
    "        [\"rule\", \"customer_id\", \"rule_score\"], ascending=[True, True, False]\n",
    "    )\n",
    "    rule_df[\"rank_within_rule\"] = rule_df.groupby([\"rule\", \"customer_id\"]).cumcount()\n",
    "\n",
    "    rule_features_df = (\n",
    "        rule_df.groupby([\"customer_id\", \"article_id\"])\n",
    "        .agg({\"rule\": \"nunique\", \"rule_score\": \"max\", \"rank_within_rule\": \"min\"})\n",
    "        .reset_index()\n",
    "    )\n",
    "    rule_features_df.columns = [\"customer_id\", \"article_id\", \"n_sources\", \"best_rule_score\", \"best_rank_within_rule\"]\n",
    "\n",
    "    # Thêm cờ nguồn\n",
    "    for rule_name in rule_df[\"rule\"].unique().to_pandas():\n",
    "        flag_df = rule_df[rule_df[\"rule\"] == rule_name][[\"customer_id\", \"article_id\"]].drop_duplicates()\n",
    "        flag_df[f\"{rule_name}_flag\"] = 1\n",
    "        rule_features_df = rule_features_df.merge(flag_df, how=\"left\", on=[\"customer_id\", \"article_id\"])\n",
    "        rule_features_df[f\"{rule_name}_flag\"] = rule_features_df[f\"{rule_name}_flag\"].fillna(0).astype(\"int8\")\n",
    "\n",
    "    # Hợp nhất ứng viên (đã thêm random_walk)\n",
    "    cand = cudf.concat([\n",
    "        popular_can,\n",
    "        recent_customer_cand,\n",
    "        cust_last_week_cand,\n",
    "        cust_last_week_pair_cand,\n",
    "        age_bucket_can,\n",
    "        random_walk_cand,\n",
    "    ]).drop_duplicates().sort_values([\"customer_id\", \"article_id\"]).reset_index(drop=True)\n",
    "    del popular_can, recent_customer_cand, cust_last_week_cand, cust_last_week_pair_cand, age_bucket_can, random_walk_cand\n",
    "\n",
    "    cand = h_can.filter_candidates(cand, t, **kwargs)\n",
    "\n",
    "    # ----- Sinh thêm đặc trưng -----\n",
    "    h_fe.create_cust_hier_features(features_df, a, kwargs[\"hier_cols\"], features_db)\n",
    "    h_fe.create_cust_hier_decay_features(features_df, a, kwargs[\"hier_cols\"], features_db,\n",
    "                                         decay_gamma=kwargs.get(\"hier_decay_gamma\", 0.3))\n",
    "    for k, v in list(features_db.items()):\n",
    "        if k.endswith(\"_decay_features\"):\n",
    "            hier = k[len(\"cust_\"):-len(\"_decay_features\")]\n",
    "            cols, df = v\n",
    "            df = df.rename(columns={\"last_seen_category_weeks_ago\": f\"last_seen_{hier}_weeks_ago\"})\n",
    "            features_db[k] = (cols, df)\n",
    "\n",
    "    h_fe.create_price_features(features_df, features_db)\n",
    "    h_fe.create_cust_features(c, features_db)\n",
    "    h_fe.create_article_cust_features(features_df, c, features_db)\n",
    "    h_fe.create_lag_features(features_df, a, kwargs[\"lag_days\"], features_db)\n",
    "    h_fe.create_rebuy_features(features_df, features_db)\n",
    "    h_fe.create_cust_t_features(features_df, a, features_db)\n",
    "    try:\n",
    "        h_fe.create_art_t_features(features_df, a, features_db)\n",
    "    except TypeError:\n",
    "        h_fe.create_art_t_features(features_df, features_db)\n",
    "    del features_df\n",
    "\n",
    "    if customers is not None:\n",
    "        cand = cand[cand[\"customer_id\"].isin(customers)]\n",
    "\n",
    "    if kwargs[\"cv\"]:\n",
    "        ground_truth_candidates = label_df[[\"customer_id\", \"article_id\"]].drop_duplicates()\n",
    "        h_cv.report_candidates(cand, ground_truth_candidates)\n",
    "        del ground_truth_candidates\n",
    "\n",
    "    cand_with_f_df = h_can.add_features_to_candidates(cand, features_db, c, a)\n",
    "    cand_with_f_df = cand_with_f_df.merge(rule_features_df, how=\"left\", on=[\"customer_id\", \"article_id\"])\n",
    "\n",
    "    for article_col in kwargs[\"article_columns\"]:\n",
    "        art_col_map = a.set_index(\"article_id\")[article_col]\n",
    "        cand_with_f_df[article_col] = cand_with_f_df[\"article_id\"].map(art_col_map)\n",
    "\n",
    "    # Fill giá trị rule cho ứng viên mới (có random_walk_flag)\n",
    "    rule_fill = {\n",
    "        \"n_sources\": 0,\n",
    "        \"best_rule_score\": -1,\n",
    "        \"best_rank_within_rule\": 127,\n",
    "        \"recent_flag\": 0,\n",
    "        \"last_weeks_flag\": 0,\n",
    "        \"pairs_flag\": 0,\n",
    "        \"age_bucket_flag\": 0,\n",
    "        \"popular_flag\": 0,\n",
    "        \"random_walk_flag\": 0,\n",
    "    }\n",
    "    cand_with_f_df = cand_with_f_df.fillna(rule_fill)\n",
    "\n",
    "    # Target encode các cột category dựa trên best_rule_score (nếu có)\n",
    "    target_col = \"best_rule_score\" if \"best_rule_score\" in cand_with_f_df.columns else None\n",
    "    for col in cand_with_f_df.columns:\n",
    "        if col in [\"customer_id\", \"article_id\"]:\n",
    "            continue\n",
    "        if str(cand_with_f_df[col].dtype) not in [\"int8\",\"int16\",\"int32\",\"int64\",\"float16\",\"float32\",\"float64\",\"bool\"]:\n",
    "            if target_col:\n",
    "                te = cand_with_f_df.groupby(col)[target_col].mean()\n",
    "                cand_with_f_df[col] = cand_with_f_df[col].map(te).fillna(0).astype(\"float32\")\n",
    "            else:\n",
    "                cand_with_f_df[col] = cand_with_f_df[col].astype(\"category\").cat.codes.astype(\"float32\")\n",
    "\n",
    "    if kwargs[\"selected_features\"] is not None:\n",
    "        cand_with_f_df = cand_with_f_df[[\"customer_id\", \"article_id\"] + kwargs[\"selected_features\"]]\n",
    "\n",
    "    assert len(cand) == len(cand_with_f_df), \"seem to have duplicates in the feature dfs\"\n",
    "    del cand\n",
    "\n",
    "    return cand_with_f_df, label_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T04:17:39.420185Z",
     "iopub.status.busy": "2026-01-02T04:17:39.419826Z",
     "iopub.status.idle": "2026-01-02T04:17:39.438990Z",
     "shell.execute_reply": "2026-01-02T04:17:39.438346Z",
     "shell.execute_reply.started": "2026-01-02T04:17:39.420163Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_model_score(ids_df, preds, truth_df):\n",
    "    predictions = h_modeling.create_predictions(ids_df, preds)\n",
    "    true_labels = h_cv.ground_truth(truth_df).set_index(\"customer_id\")[\"prediction\"]\n",
    "    score = round(h_cv.comp_average_precision(true_labels, predictions),5)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters - one place for all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T04:17:39.440024Z",
     "iopub.status.busy": "2026-01-02T04:17:39.439740Z",
     "iopub.status.idle": "2026-01-02T04:17:39.453246Z",
     "shell.execute_reply": "2026-01-02T04:17:39.452570Z",
     "shell.execute_reply.started": "2026-01-02T04:17:39.439993Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cấu hình chạy CV (đa tuần, tăng ứng viên/estimators + random walk)\n",
    "cv_params = {\n",
    "    \"cv\": True,                     # bật báo cáo recall ứng viên\n",
    "    \"feature_periods\": 105,         # dùng 105 tuần lịch sử cho feature\n",
    "    \"label_week\": 104,              # tuần label mặc định, sẽ bị override bởi cv_weeks\n",
    "    \"index_to_id_dict_path\": index_to_id_dict_path,\n",
    "    \"pairs_file_version\": \"_v3_5_ex\",\n",
    "    \"num_recent_candidates\": 120,    # tăng số ứng viên recent để nâng recall\n",
    "    \"num_recent_articles\": 30,      # tăng bài phổ biến/age bucket\n",
    "    \"hier_col\": \"department_no\",\n",
    "    \"ca_num_weeks\": 3,\n",
    "    \"clw_num_weeks\": 12,\n",
    "    \"clw_num_pair_weeks\": 2,\n",
    "    \"pa_num_weeks\": 2,              # kéo dài phổ biến thêm 2 tuần\n",
    "    \"num_age_buckets\": 4,\n",
    "    \"filter_recent_art_weeks\": 1,\n",
    "    \"filter_num_articles\": None,\n",
    "    \"lag_days\": [1, 3, 7, 14, 28],\n",
    "    \"article_columns\": [\"index_code\"],\n",
    "    \"hier_cols\": [\n",
    "        \"department_no\", \"section_no\", \"index_group_no\", \"index_code\",\n",
    "        \"product_type_no\", \"product_group_name\"\n",
    "    ],\n",
    "    \"hier_decay_gamma\": 0.3,\n",
    "    \"selected_features\": None,\n",
    "    # random walk with restart candidates\n",
    "    \"gd_seed_weeks\": 12,\n",
    "    \"gd_seed_articles\": 12,\n",
    "    \"gd_steps\": 3,\n",
    "    \"gd_restart_prob\": \"adaptive\",\n",
    "    \"gd_topk\": 24,\n",
    "    \"gd_weight_col\": \"customer_count\",\n",
    "    \"gd_recency_weight\": True,\n",
    "    \"gd_exclude_seed\": True,\n",
    "    \"lgbm_params\": {                # tăng capacity model cho CV\n",
    "        \"n_estimators\": 400,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"num_leaves\": 64,\n",
    "        \"feature_fraction\": 0.8,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"bagging_freq\": 1,\n",
    "    },\n",
    "    \"log_evaluation\": 10,\n",
    "    \"early_stopping\": 30,\n",
    "    \"eval_at\": 12,\n",
    "    \"save_model\": True,\n",
    "    \"num_concats\": 5,               # ghép 5 tuần train để tăng dữ liệu\n",
    "}\n",
    "\n",
    "# Cấu hình train/predict submit (n_estimators cao hơn, ensemble 2 model + random walk)\n",
    "sub_params = {\n",
    "    \"cv\": False,\n",
    "    \"feature_periods\": 105,\n",
    "    \"label_week\": 105,\n",
    "    \"index_to_id_dict_path\": index_to_id_dict_path,\n",
    "    \"pairs_file_version\": \"_v3_5_ex\",\n",
    "    \"num_recent_candidates\": 120,\n",
    "    \"num_recent_articles\": 30,\n",
    "    \"hier_col\": \"department_no\",\n",
    "    \"ca_num_weeks\": 3,\n",
    "    \"clw_num_weeks\": 12,\n",
    "    \"clw_num_pair_weeks\": 2,\n",
    "    \"pa_num_weeks\": 2,\n",
    "    \"num_age_buckets\": 4,\n",
    "    \"filter_recent_art_weeks\": 2,\n",
    "    \"filter_num_articles\": None,\n",
    "    \"lag_days\": [1, 3, 7, 14, 28],\n",
    "    \"article_columns\": [\"index_code\"],\n",
    "    \"hier_cols\": [\n",
    "        \"department_no\", \"section_no\", \"index_group_no\", \"index_code\",\n",
    "        \"product_type_no\", \"product_group_name\"\n",
    "    ],\n",
    "    \"hier_decay_gamma\": 0.3,\n",
    "    \"selected_features\": None,\n",
    "    # random walk with restart candidates\n",
    "    \"gd_seed_weeks\": 12,\n",
    "    \"gd_seed_articles\": 12,\n",
    "    \"gd_steps\": 3,\n",
    "    \"gd_restart_prob\": \"adaptive\",\n",
    "    \"gd_topk\": 24,\n",
    "    \"gd_weight_col\": \"customer_count\",\n",
    "    \"gd_recency_weight\": True,\n",
    "    \"gd_exclude_seed\": True,\n",
    "    \"lgbm_params\": {                # nhiều cây hơn cho submit\n",
    "        \"n_estimators\": 500,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"num_leaves\": 64,\n",
    "        \"feature_fraction\": 0.8,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"bagging_freq\": 1,\n",
    "    },\n",
    "    \"log_evaluation\": 10,\n",
    "    \"eval_at\": 12,\n",
    "    \"prediction_models\": [\"model_104\", \"model_105\"],  # ensemble 2 model\n",
    "    \"save_model\": True,\n",
    "    \"num_concats\": 5,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T04:17:39.454231Z",
     "iopub.status.busy": "2026-01-02T04:17:39.454027Z",
     "iopub.status.idle": "2026-01-02T04:17:39.469058Z",
     "shell.execute_reply": "2026-01-02T04:17:39.468408Z",
     "shell.execute_reply.started": "2026-01-02T04:17:39.454212Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cand_features_func = create_candidates_with_features_df\n",
    "scoring_func = calculate_model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T04:17:39.470031Z",
     "iopub.status.busy": "2026-01-02T04:17:39.469767Z",
     "iopub.status.idle": "2026-01-02T04:49:41.086144Z",
     "shell.execute_reply": "2026-01-02T04:49:41.085465Z",
     "shell.execute_reply.started": "2026-01-02T04:17:39.470003Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing training modeling dfs for 103...\n",
      "candidates recall: 12.72% (28,997/227,910)\n",
      "candidates precision: 0.48% (28,997/5,996,117)\n",
      "preparing training modeling dfs for 102...\n",
      "candidates recall: 13.12% (31,236/238,074)\n",
      "candidates precision: 0.51% (31,236/6,138,363)\n",
      "preparing training modeling dfs for 101...\n",
      "candidates recall: 12.46% (31,784/255,172)\n",
      "candidates precision: 0.48% (31,784/6,678,263)\n",
      "preparing training modeling dfs for 100...\n",
      "candidates recall: 11.74% (27,096/230,825)\n",
      "candidates precision: 0.42% (27,096/6,478,937)\n",
      "preparing training modeling dfs for 99...\n",
      "candidates recall: 11.53% (27,339/237,160)\n",
      "candidates precision: 0.42% (27,339/6,455,882)\n",
      "concatenating all weeks together\n",
      "preparing evaluation modeling dfs...\n",
      "candidates recall: 13.82% (29,545/213,728)\n",
      "candidates precision: 0.54% (29,545/5,455,434)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Total groups: 104751, total data: 9932461\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.675575 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12926\n",
      "[LightGBM] [Info] Number of data points in the train set: 9932461, number of used features: 74\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Total groups: 20523, total data: 1806080\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[10]\ttrain's map@12: 0.190541\ttrain's ndcg@12: 0.258017\tvalidation's map@12: 0.176294\tvalidation's ndcg@12: 0.240566\n",
      "[20]\ttrain's map@12: 0.195124\ttrain's ndcg@12: 0.264001\tvalidation's map@12: 0.18091\tvalidation's ndcg@12: 0.245902\n",
      "[30]\ttrain's map@12: 0.198264\ttrain's ndcg@12: 0.267686\tvalidation's map@12: 0.180012\tvalidation's ndcg@12: 0.2453\n",
      "[40]\ttrain's map@12: 0.200416\ttrain's ndcg@12: 0.270563\tvalidation's map@12: 0.181617\tvalidation's ndcg@12: 0.247179\n",
      "[50]\ttrain's map@12: 0.202727\ttrain's ndcg@12: 0.273511\tvalidation's map@12: 0.182546\tvalidation's ndcg@12: 0.24842\n",
      "[60]\ttrain's map@12: 0.205087\ttrain's ndcg@12: 0.276256\tvalidation's map@12: 0.183756\tvalidation's ndcg@12: 0.250277\n",
      "[70]\ttrain's map@12: 0.207267\ttrain's ndcg@12: 0.278964\tvalidation's map@12: 0.184667\tvalidation's ndcg@12: 0.25132\n",
      "[80]\ttrain's map@12: 0.209353\ttrain's ndcg@12: 0.281401\tvalidation's map@12: 0.185172\tvalidation's ndcg@12: 0.25196\n",
      "[90]\ttrain's map@12: 0.210964\ttrain's ndcg@12: 0.283508\tvalidation's map@12: 0.186351\tvalidation's ndcg@12: 0.253517\n",
      "[100]\ttrain's map@12: 0.212678\ttrain's ndcg@12: 0.285538\tvalidation's map@12: 0.186698\tvalidation's ndcg@12: 0.25408\n",
      "[110]\ttrain's map@12: 0.214355\ttrain's ndcg@12: 0.287428\tvalidation's map@12: 0.187372\tvalidation's ndcg@12: 0.255046\n",
      "[120]\ttrain's map@12: 0.215923\ttrain's ndcg@12: 0.289201\tvalidation's map@12: 0.187419\tvalidation's ndcg@12: 0.255091\n",
      "[130]\ttrain's map@12: 0.217493\ttrain's ndcg@12: 0.291016\tvalidation's map@12: 0.188237\tvalidation's ndcg@12: 0.256057\n",
      "[140]\ttrain's map@12: 0.218845\ttrain's ndcg@12: 0.292509\tvalidation's map@12: 0.188298\tvalidation's ndcg@12: 0.256088\n",
      "[150]\ttrain's map@12: 0.220173\ttrain's ndcg@12: 0.29415\tvalidation's map@12: 0.188617\tvalidation's ndcg@12: 0.256498\n",
      "[160]\ttrain's map@12: 0.221657\ttrain's ndcg@12: 0.295744\tvalidation's map@12: 0.18895\tvalidation's ndcg@12: 0.256935\n",
      "[170]\ttrain's map@12: 0.223095\ttrain's ndcg@12: 0.297394\tvalidation's map@12: 0.189364\tvalidation's ndcg@12: 0.257579\n",
      "[180]\ttrain's map@12: 0.224619\ttrain's ndcg@12: 0.299106\tvalidation's map@12: 0.190044\tvalidation's ndcg@12: 0.258127\n",
      "[190]\ttrain's map@12: 0.225895\ttrain's ndcg@12: 0.300512\tvalidation's map@12: 0.190425\tvalidation's ndcg@12: 0.258632\n",
      "[200]\ttrain's map@12: 0.22734\ttrain's ndcg@12: 0.302054\tvalidation's map@12: 0.190748\tvalidation's ndcg@12: 0.259002\n",
      "[210]\ttrain's map@12: 0.228559\ttrain's ndcg@12: 0.303378\tvalidation's map@12: 0.190985\tvalidation's ndcg@12: 0.259292\n",
      "[220]\ttrain's map@12: 0.230035\ttrain's ndcg@12: 0.304982\tvalidation's map@12: 0.191019\tvalidation's ndcg@12: 0.25966\n",
      "[230]\ttrain's map@12: 0.231529\ttrain's ndcg@12: 0.306633\tvalidation's map@12: 0.190868\tvalidation's ndcg@12: 0.25928\n",
      "Early stopping, best iteration is:\n",
      "[209]\ttrain's map@12: 0.228464\ttrain's ndcg@12: 0.303312\tvalidation's map@12: 0.191133\tvalidation's ndcg@12: 0.259402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/../input/handmhelpers1/modeling.py:272: FutureWarning: Parameter `output_class` was deprecated in version 25.06 and will be replaced with `is_classifier` in 25.08. Please use `is_classifier` in the future. For now, `output_class` parameter has been automatically converted to `is_classifier`.\n",
      "  model = ForestInference.load(model_path, model_type=\"lightgbm\", output_class=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC 0.7780\n",
      "Train score:  0.07811\n",
      "Eval AUC 0.7353\n",
      "Eval score: 0.03633\n",
      "\n",
      "\n",
      "last_weeks_flag         0\n",
      "pairs_flag              0\n",
      "recent_flag             0\n",
      "age_bucket_flag         4\n",
      "random_walk_flag        4\n",
      "                     ... \n",
      "cust_sales_channel    408\n",
      "last_1_days_count     420\n",
      "art_sales_channel     436\n",
      "rebuy_count_ratio     442\n",
      "newness_days          470\n",
      "Length: 74, dtype: int32\n",
      "Finished cv of week 104 in 0:32:01.603892. Score: 0.03633\n",
      "\n",
      "Finished all 1 cvs in 0:32:01.603890. Average cv score: 0.03633\n",
      "CPU times: user 41min 57s, sys: 36.7 s, total: 42min 33s\n",
      "Wall time: 32min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Chạy cross-validation cho các tuần 102-104 (đa tuần để ổn định hơn so với 1 tuần)\n",
    "cv_weeks = [104]\n",
    "results = h_modeling.run_all_cvs(\n",
    "    t, c, a, cand_features_func, scoring_func,\n",
    "    cv_weeks=cv_weeks, **cv_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T04:49:41.087734Z",
     "iopub.status.busy": "2026-01-02T04:49:41.087221Z",
     "iopub.status.idle": "2026-01-02T04:49:41.092298Z",
     "shell.execute_reply": "2026-01-02T04:49:41.091729Z",
     "shell.execute_reply.started": "2026-01-02T04:49:41.087709Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from cuml.fil import ForestInference as _FI\n",
    "\n",
    "_real_load = _FI.load\n",
    "\n",
    "def _load_compat(*args, output_class=None, is_classifier=None, **kwargs):\n",
    "    # helper cũ truyền output_class -> map sang is_classifier\n",
    "    if is_classifier is None and output_class is not None:\n",
    "        is_classifier = output_class\n",
    "    return _real_load(*args, is_classifier=is_classifier, **kwargs)\n",
    "\n",
    "_FI.load = staticmethod(_load_compat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T04:49:41.093488Z",
     "iopub.status.busy": "2026-01-02T04:49:41.093185Z",
     "iopub.status.idle": "2026-01-02T04:49:41.112414Z",
     "shell.execute_reply": "2026-01-02T04:49:41.111678Z",
     "shell.execute_reply.started": "2026-01-02T04:49:41.093456Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=r\".*Parameter `output_class` was deprecated.*\",\n",
    "    category=FutureWarning,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T04:49:41.113546Z",
     "iopub.status.busy": "2026-01-02T04:49:41.113310Z",
     "iopub.status.idle": "2026-01-02T04:49:41.125755Z",
     "shell.execute_reply": "2026-01-02T04:49:41.125087Z",
     "shell.execute_reply.started": "2026-01-02T04:49:41.113524Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import handmhelpers1.modeling as h_modeling\n",
    "\n",
    "def full_sub_predict_run_small_batches(t, c, a, cand_features_func, batch_splits=8, **kwargs):\n",
    "    customer_batches = []\n",
    "    n = len(c)\n",
    "    for i in range(batch_splits):\n",
    "        start = i * n // batch_splits\n",
    "        end = (i + 1) * n // batch_splits\n",
    "        customer_batches.append(c[start:end][\"customer_id\"].to_pandas().to_list())\n",
    "\n",
    "    batch_preds = []\n",
    "    for idx, customer_batch in enumerate(customer_batches):\n",
    "        print(f\"generating candidates/features for batch #{idx+1} of {len(customer_batches)}\")\n",
    "        sub_ids_df, sub_X = h_modeling.prepare_prediction_dfs(\n",
    "            t, c, a, cand_features_func, customer_batch=customer_batch, **kwargs\n",
    "        )\n",
    "        print(f\"candidate/features shape of batch: ({sub_X.shape[0]:,}, {sub_X.shape[1]})\")\n",
    "\n",
    "        model_paths = kwargs.get(\"prediction_models\")\n",
    "        if not model_paths:\n",
    "            raise ValueError(\"prediction_models is required\")\n",
    "        weights = kwargs.get(\"prediction_weights\", [1.0] * len(model_paths))\n",
    "        norm = sum(weights)\n",
    "        weights = [w / norm for w in weights]\n",
    "\n",
    "        sub_pred = 0\n",
    "        for mp, w in zip(model_paths, weights):\n",
    "            m = h_modeling.ForestInference.load(mp, model_type=\"lightgbm\", output_class=False)\n",
    "            sub_pred += w * h_modeling.pred_in_batches(m, sub_X)\n",
    "            del m\n",
    "\n",
    "        batch_preds.append(h_modeling.create_predictions(sub_ids_df, sub_pred))\n",
    "        del sub_ids_df, sub_X, sub_pred\n",
    "\n",
    "    return cudf.concat(batch_preds)\n",
    "\n",
    "# Ghi đè hàm predict gốc\n",
    "h_modeling.full_sub_predict_run = full_sub_predict_run_small_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T04:49:41.128433Z",
     "iopub.status.busy": "2026-01-02T04:49:41.128167Z",
     "iopub.status.idle": "2026-01-02T07:26:18.532473Z",
     "shell.execute_reply": "2026-01-02T07:26:18.531717Z",
     "shell.execute_reply.started": "2026-01-02T04:49:41.128412Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training ensemble model 1/4: model_105_a\n",
      "============================================================\n",
      "preparing training modeling dfs for 104...\n",
      "preparing training modeling dfs for 103...\n",
      "preparing training modeling dfs for 102...\n",
      "preparing training modeling dfs for 101...\n",
      "preparing training modeling dfs for 100...\n",
      "concatenating all weeks together\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Total groups: 106752, total data: 9851237\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.570850 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12914\n",
      "[LightGBM] [Info] Number of data points in the train set: 9851237, number of used features: 74\n",
      "[10]\ttrain's map@12: 0.189204\ttrain's ndcg@12: 0.256917\n",
      "[20]\ttrain's map@12: 0.194412\ttrain's ndcg@12: 0.263175\n",
      "[30]\ttrain's map@12: 0.197284\ttrain's ndcg@12: 0.266644\n",
      "[40]\ttrain's map@12: 0.200064\ttrain's ndcg@12: 0.270298\n",
      "[50]\ttrain's map@12: 0.202426\ttrain's ndcg@12: 0.273206\n",
      "[60]\ttrain's map@12: 0.204982\ttrain's ndcg@12: 0.276202\n",
      "[70]\ttrain's map@12: 0.206828\ttrain's ndcg@12: 0.278558\n",
      "[80]\ttrain's map@12: 0.20868\ttrain's ndcg@12: 0.280841\n",
      "[90]\ttrain's map@12: 0.210482\ttrain's ndcg@12: 0.282887\n",
      "[100]\ttrain's map@12: 0.212365\ttrain's ndcg@12: 0.285099\n",
      "[110]\ttrain's map@12: 0.214034\ttrain's ndcg@12: 0.287147\n",
      "[120]\ttrain's map@12: 0.215798\ttrain's ndcg@12: 0.28912\n",
      "[130]\ttrain's map@12: 0.217541\ttrain's ndcg@12: 0.291112\n",
      "[140]\ttrain's map@12: 0.219189\ttrain's ndcg@12: 0.293044\n",
      "[150]\ttrain's map@12: 0.220852\ttrain's ndcg@12: 0.294845\n",
      "[160]\ttrain's map@12: 0.222396\ttrain's ndcg@12: 0.296534\n",
      "[170]\ttrain's map@12: 0.223884\ttrain's ndcg@12: 0.298368\n",
      "[180]\ttrain's map@12: 0.225331\ttrain's ndcg@12: 0.299957\n",
      "[190]\ttrain's map@12: 0.22686\ttrain's ndcg@12: 0.301614\n",
      "[200]\ttrain's map@12: 0.228308\ttrain's ndcg@12: 0.303306\n",
      "[210]\ttrain's map@12: 0.229899\ttrain's ndcg@12: 0.305084\n",
      "[220]\ttrain's map@12: 0.231161\ttrain's ndcg@12: 0.306521\n",
      "[230]\ttrain's map@12: 0.23263\ttrain's ndcg@12: 0.308155\n",
      "[240]\ttrain's map@12: 0.234277\ttrain's ndcg@12: 0.309907\n",
      "[250]\ttrain's map@12: 0.235731\ttrain's ndcg@12: 0.311474\n",
      "[260]\ttrain's map@12: 0.237243\ttrain's ndcg@12: 0.313018\n",
      "[270]\ttrain's map@12: 0.238383\ttrain's ndcg@12: 0.314353\n",
      "[280]\ttrain's map@12: 0.239828\ttrain's ndcg@12: 0.315837\n",
      "[290]\ttrain's map@12: 0.241202\ttrain's ndcg@12: 0.317301\n",
      "[300]\ttrain's map@12: 0.242638\ttrain's ndcg@12: 0.318796\n",
      "[310]\ttrain's map@12: 0.243919\ttrain's ndcg@12: 0.320138\n",
      "[320]\ttrain's map@12: 0.245217\ttrain's ndcg@12: 0.321499\n",
      "[330]\ttrain's map@12: 0.246433\ttrain's ndcg@12: 0.322845\n",
      "[340]\ttrain's map@12: 0.247649\ttrain's ndcg@12: 0.324175\n",
      "[350]\ttrain's map@12: 0.248786\ttrain's ndcg@12: 0.325382\n",
      "[360]\ttrain's map@12: 0.249977\ttrain's ndcg@12: 0.326658\n",
      "[370]\ttrain's map@12: 0.251243\ttrain's ndcg@12: 0.32803\n",
      "[380]\ttrain's map@12: 0.252455\ttrain's ndcg@12: 0.329343\n",
      "[390]\ttrain's map@12: 0.253747\ttrain's ndcg@12: 0.330602\n",
      "[400]\ttrain's map@12: 0.254946\ttrain's ndcg@12: 0.331848\n",
      "[410]\ttrain's map@12: 0.256163\ttrain's ndcg@12: 0.333127\n",
      "[420]\ttrain's map@12: 0.257376\ttrain's ndcg@12: 0.334407\n",
      "[430]\ttrain's map@12: 0.258525\ttrain's ndcg@12: 0.335685\n",
      "[440]\ttrain's map@12: 0.259743\ttrain's ndcg@12: 0.33706\n",
      "[450]\ttrain's map@12: 0.260781\ttrain's ndcg@12: 0.338135\n",
      "[460]\ttrain's map@12: 0.262175\ttrain's ndcg@12: 0.339595\n",
      "[470]\ttrain's map@12: 0.263365\ttrain's ndcg@12: 0.340826\n",
      "[480]\ttrain's map@12: 0.264585\ttrain's ndcg@12: 0.342162\n",
      "[490]\ttrain's map@12: 0.265742\ttrain's ndcg@12: 0.343315\n",
      "[500]\ttrain's map@12: 0.266893\ttrain's ndcg@12: 0.344587\n",
      "Train AUC 0.7910\n",
      "Train score:  0.08473\n",
      "Model 'model_105_a' trained successfully\n",
      "\n",
      "\n",
      "============================================================\n",
      "Training ensemble model 2/4: model_105_b\n",
      "============================================================\n",
      "preparing training modeling dfs for 104...\n",
      "preparing training modeling dfs for 103...\n",
      "preparing training modeling dfs for 102...\n",
      "preparing training modeling dfs for 101...\n",
      "preparing training modeling dfs for 100...\n",
      "concatenating all weeks together\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Total groups: 106752, total data: 9851243\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.730792 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12910\n",
      "[LightGBM] [Info] Number of data points in the train set: 9851243, number of used features: 74\n",
      "[10]\ttrain's map@12: 0.191634\ttrain's ndcg@12: 0.260096\n",
      "[20]\ttrain's map@12: 0.197717\ttrain's ndcg@12: 0.267363\n",
      "[30]\ttrain's map@12: 0.201238\ttrain's ndcg@12: 0.271865\n",
      "[40]\ttrain's map@12: 0.204241\ttrain's ndcg@12: 0.275527\n",
      "[50]\ttrain's map@12: 0.206919\ttrain's ndcg@12: 0.278642\n",
      "[60]\ttrain's map@12: 0.209544\ttrain's ndcg@12: 0.281793\n",
      "[70]\ttrain's map@12: 0.211864\ttrain's ndcg@12: 0.284547\n",
      "[80]\ttrain's map@12: 0.213909\ttrain's ndcg@12: 0.286936\n",
      "[90]\ttrain's map@12: 0.2162\ttrain's ndcg@12: 0.289719\n",
      "[100]\ttrain's map@12: 0.218346\ttrain's ndcg@12: 0.292094\n",
      "[110]\ttrain's map@12: 0.22077\ttrain's ndcg@12: 0.294833\n",
      "[120]\ttrain's map@12: 0.222727\ttrain's ndcg@12: 0.297254\n",
      "[130]\ttrain's map@12: 0.224823\ttrain's ndcg@12: 0.299603\n",
      "[140]\ttrain's map@12: 0.22693\ttrain's ndcg@12: 0.30191\n",
      "[150]\ttrain's map@12: 0.22869\ttrain's ndcg@12: 0.303792\n",
      "[160]\ttrain's map@12: 0.230758\ttrain's ndcg@12: 0.306069\n",
      "[170]\ttrain's map@12: 0.232796\ttrain's ndcg@12: 0.308338\n",
      "[180]\ttrain's map@12: 0.234531\ttrain's ndcg@12: 0.310351\n",
      "[190]\ttrain's map@12: 0.236431\ttrain's ndcg@12: 0.312417\n",
      "[200]\ttrain's map@12: 0.238102\ttrain's ndcg@12: 0.314262\n",
      "[210]\ttrain's map@12: 0.240193\ttrain's ndcg@12: 0.31659\n",
      "[220]\ttrain's map@12: 0.242284\ttrain's ndcg@12: 0.318737\n",
      "[230]\ttrain's map@12: 0.244165\ttrain's ndcg@12: 0.320689\n",
      "[240]\ttrain's map@12: 0.24591\ttrain's ndcg@12: 0.322606\n",
      "[250]\ttrain's map@12: 0.247466\ttrain's ndcg@12: 0.324445\n",
      "[260]\ttrain's map@12: 0.249184\ttrain's ndcg@12: 0.326344\n",
      "[270]\ttrain's map@12: 0.251022\ttrain's ndcg@12: 0.328318\n",
      "[280]\ttrain's map@12: 0.252958\ttrain's ndcg@12: 0.330427\n",
      "[290]\ttrain's map@12: 0.254628\ttrain's ndcg@12: 0.332177\n",
      "[300]\ttrain's map@12: 0.256349\ttrain's ndcg@12: 0.333926\n",
      "[310]\ttrain's map@12: 0.257742\ttrain's ndcg@12: 0.335507\n",
      "[320]\ttrain's map@12: 0.259561\ttrain's ndcg@12: 0.337453\n",
      "[330]\ttrain's map@12: 0.26123\ttrain's ndcg@12: 0.339093\n",
      "[340]\ttrain's map@12: 0.262778\ttrain's ndcg@12: 0.340893\n",
      "[350]\ttrain's map@12: 0.264424\ttrain's ndcg@12: 0.342637\n",
      "[360]\ttrain's map@12: 0.266112\ttrain's ndcg@12: 0.344348\n",
      "[370]\ttrain's map@12: 0.267583\ttrain's ndcg@12: 0.345842\n",
      "[380]\ttrain's map@12: 0.269012\ttrain's ndcg@12: 0.347395\n",
      "[390]\ttrain's map@12: 0.270687\ttrain's ndcg@12: 0.349113\n",
      "[400]\ttrain's map@12: 0.272234\ttrain's ndcg@12: 0.350628\n",
      "[410]\ttrain's map@12: 0.273889\ttrain's ndcg@12: 0.352355\n",
      "[420]\ttrain's map@12: 0.27545\ttrain's ndcg@12: 0.353999\n",
      "[430]\ttrain's map@12: 0.277208\ttrain's ndcg@12: 0.355783\n",
      "[440]\ttrain's map@12: 0.278844\ttrain's ndcg@12: 0.357515\n",
      "[450]\ttrain's map@12: 0.280278\ttrain's ndcg@12: 0.359112\n",
      "[460]\ttrain's map@12: 0.281873\ttrain's ndcg@12: 0.360748\n",
      "[470]\ttrain's map@12: 0.283465\ttrain's ndcg@12: 0.362338\n",
      "[480]\ttrain's map@12: 0.285085\ttrain's ndcg@12: 0.364083\n",
      "[490]\ttrain's map@12: 0.286583\ttrain's ndcg@12: 0.365657\n",
      "[500]\ttrain's map@12: 0.28807\ttrain's ndcg@12: 0.367208\n",
      "Train AUC 0.8010\n",
      "Train score:  0.08725\n",
      "Model 'model_105_b' trained successfully\n",
      "\n",
      "\n",
      "============================================================\n",
      "Training ensemble model 3/4: model_105_lr003_ne800\n",
      "============================================================\n",
      "preparing training modeling dfs for 104...\n",
      "preparing training modeling dfs for 103...\n",
      "preparing training modeling dfs for 102...\n",
      "preparing training modeling dfs for 101...\n",
      "preparing training modeling dfs for 100...\n",
      "concatenating all weeks together\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Total groups: 106752, total data: 9851145\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.774403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12921\n",
      "[LightGBM] [Info] Number of data points in the train set: 9851145, number of used features: 74\n",
      "[10]\ttrain's map@12: 0.191041\ttrain's ndcg@12: 0.259627\n",
      "[20]\ttrain's map@12: 0.196054\ttrain's ndcg@12: 0.265307\n",
      "[30]\ttrain's map@12: 0.198509\ttrain's ndcg@12: 0.268529\n",
      "[40]\ttrain's map@12: 0.200288\ttrain's ndcg@12: 0.2707\n",
      "[50]\ttrain's map@12: 0.201838\ttrain's ndcg@12: 0.272726\n",
      "[60]\ttrain's map@12: 0.203453\ttrain's ndcg@12: 0.274896\n",
      "[70]\ttrain's map@12: 0.205402\ttrain's ndcg@12: 0.277113\n",
      "[80]\ttrain's map@12: 0.206543\ttrain's ndcg@12: 0.278522\n",
      "[90]\ttrain's map@12: 0.208299\ttrain's ndcg@12: 0.280704\n",
      "[100]\ttrain's map@12: 0.209752\ttrain's ndcg@12: 0.282437\n",
      "[110]\ttrain's map@12: 0.211507\ttrain's ndcg@12: 0.284382\n",
      "[120]\ttrain's map@12: 0.212875\ttrain's ndcg@12: 0.286022\n",
      "[130]\ttrain's map@12: 0.214399\ttrain's ndcg@12: 0.287858\n",
      "[140]\ttrain's map@12: 0.215635\ttrain's ndcg@12: 0.289314\n",
      "[150]\ttrain's map@12: 0.217008\ttrain's ndcg@12: 0.290881\n",
      "[160]\ttrain's map@12: 0.218453\ttrain's ndcg@12: 0.292402\n",
      "[170]\ttrain's map@12: 0.219866\ttrain's ndcg@12: 0.293977\n",
      "[180]\ttrain's map@12: 0.221073\ttrain's ndcg@12: 0.295388\n",
      "[190]\ttrain's map@12: 0.222545\ttrain's ndcg@12: 0.297065\n",
      "[200]\ttrain's map@12: 0.22389\ttrain's ndcg@12: 0.298552\n",
      "[210]\ttrain's map@12: 0.225097\ttrain's ndcg@12: 0.299931\n",
      "[220]\ttrain's map@12: 0.226458\ttrain's ndcg@12: 0.301506\n",
      "[230]\ttrain's map@12: 0.227608\ttrain's ndcg@12: 0.302775\n",
      "[240]\ttrain's map@12: 0.228823\ttrain's ndcg@12: 0.304171\n",
      "[250]\ttrain's map@12: 0.230023\ttrain's ndcg@12: 0.305485\n",
      "[260]\ttrain's map@12: 0.231163\ttrain's ndcg@12: 0.306738\n",
      "[270]\ttrain's map@12: 0.232348\ttrain's ndcg@12: 0.308122\n",
      "[280]\ttrain's map@12: 0.233487\ttrain's ndcg@12: 0.309419\n",
      "[290]\ttrain's map@12: 0.234844\ttrain's ndcg@12: 0.310831\n",
      "[300]\ttrain's map@12: 0.236042\ttrain's ndcg@12: 0.312065\n",
      "[310]\ttrain's map@12: 0.237228\ttrain's ndcg@12: 0.313368\n",
      "[320]\ttrain's map@12: 0.238653\ttrain's ndcg@12: 0.314831\n",
      "[330]\ttrain's map@12: 0.239634\ttrain's ndcg@12: 0.315936\n",
      "[340]\ttrain's map@12: 0.240783\ttrain's ndcg@12: 0.31726\n",
      "[350]\ttrain's map@12: 0.242038\ttrain's ndcg@12: 0.318472\n",
      "[360]\ttrain's map@12: 0.243227\ttrain's ndcg@12: 0.319702\n",
      "[370]\ttrain's map@12: 0.244139\ttrain's ndcg@12: 0.320798\n",
      "[380]\ttrain's map@12: 0.245387\ttrain's ndcg@12: 0.322138\n",
      "[390]\ttrain's map@12: 0.246445\ttrain's ndcg@12: 0.323329\n",
      "[400]\ttrain's map@12: 0.247664\ttrain's ndcg@12: 0.324608\n",
      "[410]\ttrain's map@12: 0.248881\ttrain's ndcg@12: 0.325974\n",
      "[420]\ttrain's map@12: 0.250032\ttrain's ndcg@12: 0.327215\n",
      "[430]\ttrain's map@12: 0.251116\ttrain's ndcg@12: 0.328401\n",
      "[440]\ttrain's map@12: 0.252157\ttrain's ndcg@12: 0.329497\n",
      "[450]\ttrain's map@12: 0.253279\ttrain's ndcg@12: 0.330702\n",
      "[460]\ttrain's map@12: 0.254406\ttrain's ndcg@12: 0.331922\n",
      "[470]\ttrain's map@12: 0.255507\ttrain's ndcg@12: 0.333115\n",
      "[480]\ttrain's map@12: 0.256561\ttrain's ndcg@12: 0.33421\n",
      "[490]\ttrain's map@12: 0.257549\ttrain's ndcg@12: 0.335222\n",
      "[500]\ttrain's map@12: 0.258522\ttrain's ndcg@12: 0.336282\n",
      "[510]\ttrain's map@12: 0.259575\ttrain's ndcg@12: 0.337434\n",
      "[520]\ttrain's map@12: 0.260577\ttrain's ndcg@12: 0.338462\n",
      "[530]\ttrain's map@12: 0.261666\ttrain's ndcg@12: 0.339652\n",
      "[540]\ttrain's map@12: 0.262745\ttrain's ndcg@12: 0.340811\n",
      "[550]\ttrain's map@12: 0.263803\ttrain's ndcg@12: 0.341913\n",
      "[560]\ttrain's map@12: 0.264849\ttrain's ndcg@12: 0.343045\n",
      "[570]\ttrain's map@12: 0.265922\ttrain's ndcg@12: 0.344128\n",
      "[580]\ttrain's map@12: 0.267048\ttrain's ndcg@12: 0.345231\n",
      "[590]\ttrain's map@12: 0.268208\ttrain's ndcg@12: 0.346443\n",
      "[600]\ttrain's map@12: 0.269115\ttrain's ndcg@12: 0.347397\n",
      "[610]\ttrain's map@12: 0.270163\ttrain's ndcg@12: 0.348559\n",
      "[620]\ttrain's map@12: 0.271225\ttrain's ndcg@12: 0.349691\n",
      "[630]\ttrain's map@12: 0.272245\ttrain's ndcg@12: 0.350728\n",
      "[640]\ttrain's map@12: 0.273183\ttrain's ndcg@12: 0.351719\n",
      "[650]\ttrain's map@12: 0.274243\ttrain's ndcg@12: 0.352798\n",
      "[660]\ttrain's map@12: 0.275259\ttrain's ndcg@12: 0.353865\n",
      "[670]\ttrain's map@12: 0.27623\ttrain's ndcg@12: 0.354923\n",
      "[680]\ttrain's map@12: 0.277255\ttrain's ndcg@12: 0.355933\n",
      "[690]\ttrain's map@12: 0.27812\ttrain's ndcg@12: 0.356898\n",
      "[700]\ttrain's map@12: 0.278857\ttrain's ndcg@12: 0.357751\n",
      "[710]\ttrain's map@12: 0.279817\ttrain's ndcg@12: 0.358812\n",
      "[720]\ttrain's map@12: 0.280777\ttrain's ndcg@12: 0.359737\n",
      "[730]\ttrain's map@12: 0.281765\ttrain's ndcg@12: 0.360862\n",
      "[740]\ttrain's map@12: 0.282819\ttrain's ndcg@12: 0.361966\n",
      "[750]\ttrain's map@12: 0.283653\ttrain's ndcg@12: 0.362837\n",
      "[760]\ttrain's map@12: 0.284741\ttrain's ndcg@12: 0.36391\n",
      "[770]\ttrain's map@12: 0.285652\ttrain's ndcg@12: 0.364861\n",
      "[780]\ttrain's map@12: 0.286704\ttrain's ndcg@12: 0.365906\n",
      "[790]\ttrain's map@12: 0.287619\ttrain's ndcg@12: 0.366922\n",
      "[800]\ttrain's map@12: 0.288645\ttrain's ndcg@12: 0.367946\n",
      "Train AUC 0.8013\n",
      "Train score:  0.08774\n",
      "Model 'model_105_lr003_ne800' trained successfully\n",
      "\n",
      "\n",
      "============================================================\n",
      "Training ensemble model 4/4: model_105_leaves128\n",
      "============================================================\n",
      "preparing training modeling dfs for 104...\n",
      "preparing training modeling dfs for 103...\n",
      "preparing training modeling dfs for 102...\n",
      "preparing training modeling dfs for 101...\n",
      "preparing training modeling dfs for 100...\n",
      "concatenating all weeks together\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Total groups: 106752, total data: 9851248\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.100999 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12919\n",
      "[LightGBM] [Info] Number of data points in the train set: 9851248, number of used features: 74\n",
      "[10]\ttrain's map@12: 0.194844\ttrain's ndcg@12: 0.264204\n",
      "[20]\ttrain's map@12: 0.201527\ttrain's ndcg@12: 0.272179\n",
      "[30]\ttrain's map@12: 0.205356\ttrain's ndcg@12: 0.276818\n",
      "[40]\ttrain's map@12: 0.208442\ttrain's ndcg@12: 0.280489\n",
      "[50]\ttrain's map@12: 0.211444\ttrain's ndcg@12: 0.284179\n",
      "[60]\ttrain's map@12: 0.214428\ttrain's ndcg@12: 0.287868\n",
      "[70]\ttrain's map@12: 0.217377\ttrain's ndcg@12: 0.291309\n",
      "[80]\ttrain's map@12: 0.219737\ttrain's ndcg@12: 0.294007\n",
      "[90]\ttrain's map@12: 0.222684\ttrain's ndcg@12: 0.297382\n",
      "[100]\ttrain's map@12: 0.225345\ttrain's ndcg@12: 0.300493\n",
      "[110]\ttrain's map@12: 0.228038\ttrain's ndcg@12: 0.303487\n",
      "[120]\ttrain's map@12: 0.230729\ttrain's ndcg@12: 0.306374\n",
      "[130]\ttrain's map@12: 0.233082\ttrain's ndcg@12: 0.309071\n",
      "[140]\ttrain's map@12: 0.235547\ttrain's ndcg@12: 0.311764\n",
      "[150]\ttrain's map@12: 0.238027\ttrain's ndcg@12: 0.314514\n",
      "[160]\ttrain's map@12: 0.240387\ttrain's ndcg@12: 0.317091\n",
      "[170]\ttrain's map@12: 0.242718\ttrain's ndcg@12: 0.319663\n",
      "[180]\ttrain's map@12: 0.245196\ttrain's ndcg@12: 0.322324\n",
      "[190]\ttrain's map@12: 0.247521\ttrain's ndcg@12: 0.324804\n",
      "[200]\ttrain's map@12: 0.250258\ttrain's ndcg@12: 0.32767\n",
      "[210]\ttrain's map@12: 0.252671\ttrain's ndcg@12: 0.330335\n",
      "[220]\ttrain's map@12: 0.255139\ttrain's ndcg@12: 0.332899\n",
      "[230]\ttrain's map@12: 0.257359\ttrain's ndcg@12: 0.335323\n",
      "[240]\ttrain's map@12: 0.259894\ttrain's ndcg@12: 0.337999\n",
      "[250]\ttrain's map@12: 0.262248\ttrain's ndcg@12: 0.340581\n",
      "[260]\ttrain's map@12: 0.264487\ttrain's ndcg@12: 0.342835\n",
      "[270]\ttrain's map@12: 0.266763\ttrain's ndcg@12: 0.345282\n",
      "[280]\ttrain's map@12: 0.268949\ttrain's ndcg@12: 0.347542\n",
      "[290]\ttrain's map@12: 0.271224\ttrain's ndcg@12: 0.349894\n",
      "[300]\ttrain's map@12: 0.273302\ttrain's ndcg@12: 0.352098\n",
      "[310]\ttrain's map@12: 0.275434\ttrain's ndcg@12: 0.354354\n",
      "[320]\ttrain's map@12: 0.27758\ttrain's ndcg@12: 0.356618\n",
      "[330]\ttrain's map@12: 0.279696\ttrain's ndcg@12: 0.358859\n",
      "[340]\ttrain's map@12: 0.281804\ttrain's ndcg@12: 0.361064\n",
      "[350]\ttrain's map@12: 0.283958\ttrain's ndcg@12: 0.363302\n",
      "[360]\ttrain's map@12: 0.286069\ttrain's ndcg@12: 0.365458\n",
      "[370]\ttrain's map@12: 0.288052\ttrain's ndcg@12: 0.36761\n",
      "[380]\ttrain's map@12: 0.289924\ttrain's ndcg@12: 0.36949\n",
      "[390]\ttrain's map@12: 0.291861\ttrain's ndcg@12: 0.371526\n",
      "[400]\ttrain's map@12: 0.293974\ttrain's ndcg@12: 0.373822\n",
      "[410]\ttrain's map@12: 0.295864\ttrain's ndcg@12: 0.37578\n",
      "[420]\ttrain's map@12: 0.297848\ttrain's ndcg@12: 0.377785\n",
      "[430]\ttrain's map@12: 0.299685\ttrain's ndcg@12: 0.379641\n",
      "[440]\ttrain's map@12: 0.301792\ttrain's ndcg@12: 0.381715\n",
      "[450]\ttrain's map@12: 0.303714\ttrain's ndcg@12: 0.383792\n",
      "[460]\ttrain's map@12: 0.305675\ttrain's ndcg@12: 0.385865\n",
      "[470]\ttrain's map@12: 0.307506\ttrain's ndcg@12: 0.387842\n",
      "[480]\ttrain's map@12: 0.309366\ttrain's ndcg@12: 0.389784\n",
      "[490]\ttrain's map@12: 0.311024\ttrain's ndcg@12: 0.391495\n",
      "[500]\ttrain's map@12: 0.312895\ttrain's ndcg@12: 0.393473\n",
      "[510]\ttrain's map@12: 0.314818\ttrain's ndcg@12: 0.395435\n",
      "[520]\ttrain's map@12: 0.316879\ttrain's ndcg@12: 0.397481\n",
      "[530]\ttrain's map@12: 0.319132\ttrain's ndcg@12: 0.39959\n",
      "[540]\ttrain's map@12: 0.320781\ttrain's ndcg@12: 0.401328\n",
      "[550]\ttrain's map@12: 0.32265\ttrain's ndcg@12: 0.40326\n",
      "[560]\ttrain's map@12: 0.32437\ttrain's ndcg@12: 0.405012\n",
      "[570]\ttrain's map@12: 0.326289\ttrain's ndcg@12: 0.407036\n",
      "[580]\ttrain's map@12: 0.328185\ttrain's ndcg@12: 0.408972\n",
      "[590]\ttrain's map@12: 0.330032\ttrain's ndcg@12: 0.410796\n",
      "[600]\ttrain's map@12: 0.332182\ttrain's ndcg@12: 0.412926\n",
      "Train AUC 0.8198\n",
      "Train score:  0.09244\n",
      "Model 'model_105_leaves128' trained successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_configs = [\n",
    "    {\"model_name\": \"model_105_a\", \"seed\": 13, \"lgbm_params\": {\"num_leaves\": 72}},\n",
    "    {\"model_name\": \"model_105_b\", \"lgbm_params\": {\"num_leaves\": 96}},\n",
    "    {\"model_name\": \"model_105_lr003_ne800\", \"lgbm_params\": {\"learning_rate\": 0.03, \"n_estimators\": 800, \"num_leaves\": 96}},\n",
    "    {\"model_name\": \"model_105_leaves128\", \"lgbm_params\": {\"learning_rate\": 0.05, \"n_estimators\": 600, \"num_leaves\": 128, \"feature_fraction\": 0.75}},\n",
    "]\n",
    "trained_models = h_modeling.train_ensemble_models(\n",
    "    t, c, a, cand_features_func, scoring_func, ensemble_configs, sub_params\n",
    ")\n",
    "sub_params[\"prediction_models\"] = trained_models  # dùng luôn cho predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T08:26:25.558243Z",
     "iopub.status.busy": "2026-01-02T08:26:25.557460Z",
     "iopub.status.idle": "2026-01-02T08:55:01.048689Z",
     "shell.execute_reply": "2026-01-02T08:55:01.048102Z",
     "shell.execute_reply.started": "2026-01-02T08:26:25.558211Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating candidates/features for batch #1 of 8\n",
      "candidate/features shape of batch: (11,516,806, 74)\n",
      "generating candidates/features for batch #2 of 8\n",
      "candidate/features shape of batch: (11,490,733, 74)\n",
      "generating candidates/features for batch #3 of 8\n",
      "candidate/features shape of batch: (11,499,889, 74)\n",
      "generating candidates/features for batch #4 of 8\n",
      "candidate/features shape of batch: (11,504,008, 74)\n",
      "generating candidates/features for batch #5 of 8\n",
      "candidate/features shape of batch: (11,511,727, 74)\n",
      "generating candidates/features for batch #6 of 8\n",
      "candidate/features shape of batch: (11,502,548, 74)\n",
      "generating candidates/features for batch #7 of 8\n",
      "candidate/features shape of batch: (11,488,772, 74)\n",
      "generating candidates/features for batch #8 of 8\n",
      "candidate/features shape of batch: (11,494,976, 74)\n"
     ]
    }
   ],
   "source": [
    "# # Sau khi train xong hai model này\n",
    "# sub_params[\"prediction_models\"] = [\n",
    "#     \"model_105_leaves128\",\n",
    "#     \"model_105_lr003_ne800\",\n",
    "# ]\n",
    "\n",
    "# # Nếu có điểm CV, gán trọng số theo điểm (ví dụ)\n",
    "# sub_params[\"prediction_weights\"] = [0.45, 0.55]\n",
    "\n",
    "# # Predict\n",
    "# predictions = h_modeling.full_sub_predict_run(\n",
    "#     t, c, a, cand_features_func,\n",
    "#     batch_splits=8,\n",
    "#     **sub_params\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T08:55:08.856792Z",
     "iopub.status.busy": "2026-01-02T08:55:08.856183Z",
     "iopub.status.idle": "2026-01-02T08:55:44.480367Z",
     "shell.execute_reply": "2026-01-02T08:55:44.479628Z",
     "shell.execute_reply.started": "2026-01-02T08:55:08.856759Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "      <td>0568601043 0779781015 0568601044 0762846031 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n",
       "      <td>0863583001 0714790020 0448509014 0906352001 09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>0794321007 0805000001 0794321008 0573085028 08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...</td>\n",
       "      <td>0861803009 0730683050 0852584001 0791587001 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...</td>\n",
       "      <td>0791587021 0730683050 0791587001 0928206001 08...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_id  \\\n",
       "0  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...   \n",
       "1  0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...   \n",
       "2  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   \n",
       "3  00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...   \n",
       "4  00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...   \n",
       "\n",
       "                                          prediction  \n",
       "0  0568601043 0779781015 0568601044 0762846031 07...  \n",
       "1  0863583001 0714790020 0448509014 0906352001 09...  \n",
       "2  0794321007 0805000001 0794321008 0573085028 08...  \n",
       "3  0861803009 0730683050 0852584001 0791587001 07...  \n",
       "4  0791587021 0730683050 0791587001 0928206001 08...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1371980, 2)\n"
     ]
    }
   ],
   "source": [
    "# sub = h_sub.create_sub(c[\"customer_id\"], predictions, index_to_id_dict_path)\n",
    "# sub.to_csv('dev_submission_2.csv', index=False)\n",
    "\n",
    "# display(sub.head())\n",
    "# print(sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T07:26:18.533687Z",
     "iopub.status.busy": "2026-01-02T07:26:18.533414Z",
     "iopub.status.idle": "2026-01-02T07:55:37.260992Z",
     "shell.execute_reply": "2026-01-02T07:55:37.260139Z",
     "shell.execute_reply.started": "2026-01-02T07:26:18.533652Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating candidates/features for batch #1 of 8\n",
      "candidate/features shape of batch: (11,516,807, 74)\n",
      "generating candidates/features for batch #2 of 8\n",
      "candidate/features shape of batch: (11,490,738, 74)\n",
      "generating candidates/features for batch #3 of 8\n",
      "candidate/features shape of batch: (11,499,888, 74)\n",
      "generating candidates/features for batch #4 of 8\n",
      "candidate/features shape of batch: (11,504,008, 74)\n",
      "generating candidates/features for batch #5 of 8\n",
      "candidate/features shape of batch: (11,511,720, 74)\n",
      "generating candidates/features for batch #6 of 8\n",
      "candidate/features shape of batch: (11,502,539, 74)\n",
      "generating candidates/features for batch #7 of 8\n",
      "candidate/features shape of batch: (11,488,772, 74)\n",
      "generating candidates/features for batch #8 of 8\n",
      "candidate/features shape of batch: (11,494,989, 74)\n",
      "CPU times: user 27min 34s, sys: 1min 44s, total: 29min 19s\n",
      "Wall time: 29min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gc.collect()\n",
    "# Train full dữ liệu submit và lưu model theo sub_params\n",
    "# h_modeling.full_sub_train_run(t, c, a, cand_features_func, scoring_func, **sub_params)\n",
    "# Predict theo batch nhỏ (batch_splits=8) để tránh OOM, dùng ensemble model_104/model_105\n",
    "predictions = h_modeling.full_sub_predict_run(\n",
    "    t, c, a, cand_features_func, batch_splits=8, **sub_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T07:55:37.262903Z",
     "iopub.status.busy": "2026-01-02T07:55:37.262220Z",
     "iopub.status.idle": "2026-01-02T07:56:13.239545Z",
     "shell.execute_reply": "2026-01-02T07:56:13.238787Z",
     "shell.execute_reply.started": "2026-01-02T07:55:37.262834Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "      <td>0568601043 0779781015 0568601044 0762846031 08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n",
       "      <td>0863583001 0714790020 0906352001 0448509014 09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>0794321007 0805000001 0794321008 0573085028 09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...</td>\n",
       "      <td>0730683050 0861803009 0852584001 0791587001 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...</td>\n",
       "      <td>0791587021 0791587001 0730683050 0866731001 09...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_id  \\\n",
       "0  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...   \n",
       "1  0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...   \n",
       "2  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   \n",
       "3  00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...   \n",
       "4  00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...   \n",
       "\n",
       "                                          prediction  \n",
       "0  0568601043 0779781015 0568601044 0762846031 08...  \n",
       "1  0863583001 0714790020 0906352001 0448509014 09...  \n",
       "2  0794321007 0805000001 0794321008 0573085028 09...  \n",
       "3  0730683050 0861803009 0852584001 0791587001 07...  \n",
       "4  0791587021 0791587001 0730683050 0866731001 09...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1371980, 2)\n"
     ]
    }
   ],
   "source": [
    "sub = h_sub.create_sub(c[\"customer_id\"], predictions, index_to_id_dict_path)\n",
    "sub.to_csv('dev_submission.csv', index=False)\n",
    "\n",
    "display(sub.head())\n",
    "print(sub.shape)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 3103714,
     "sourceId": 31254,
     "sourceType": "competition"
    },
    {
     "datasetId": 9172279,
     "sourceId": 14367343,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
