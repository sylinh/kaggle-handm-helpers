{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T06:49:56.231218Z",
     "iopub.status.busy": "2025-12-29T06:49:56.230991Z",
     "iopub.status.idle": "2025-12-29T06:50:00.311218Z",
     "shell.execute_reply": "2025-12-29T06:50:00.310255Z",
     "shell.execute_reply.started": "2025-12-29T06:49:56.231196Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.53 s, sys: 716 ms, total: 4.25 s\n",
      "Wall time: 4.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "from datetime import datetime\n",
    "import gc\n",
    "import pickle as pkl\n",
    "import shelve\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cudf\n",
    "\n",
    "sys.path.append(\"../input/\")\n",
    "from handmhelpers import io as h_io, sub as h_sub, cv as h_cv, fe as h_fe\n",
    "from handmhelpers import modeling as h_modeling, candidates as h_can, pairs as h_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and convert data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T06:50:00.314183Z",
     "iopub.status.busy": "2025-12-29T06:50:00.313721Z",
     "iopub.status.idle": "2025-12-29T06:50:00.321703Z",
     "shell.execute_reply": "2025-12-29T06:50:00.320971Z",
     "shell.execute_reply.started": "2025-12-29T06:50:00.314139Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import cudf\n",
    "import numpy as np\n",
    "\n",
    "def patched_day_week_numbers(dates: cudf.Series):\n",
    "    pd_dates = cudf.to_datetime(dates)\n",
    "    unique_dates = cudf.Series(pd_dates.unique())\n",
    "    numbered_days = unique_dates - unique_dates.min() + timedelta(1)\n",
    "    numbered_days = numbered_days.dt.days\n",
    "    extra_days = numbered_days.max() % 7\n",
    "    numbered_days -= extra_days\n",
    "    day_weeks = (numbered_days + 6) // 7  # không dùng applymap\n",
    "    day_weeks_map = cudf.DataFrame({\"day_weeks\": day_weeks, \"unique_dates\": unique_dates}).set_index(\"unique_dates\")[\"day_weeks\"]\n",
    "    all_day_weeks = pd_dates.map(day_weeks_map).astype(\"int8\")\n",
    "    return all_day_weeks\n",
    "\n",
    "import handmhelpers.fe as h_fe\n",
    "h_fe.day_week_numbers = patched_day_week_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T06:50:00.323419Z",
     "iopub.status.busy": "2025-12-29T06:50:00.322872Z",
     "iopub.status.idle": "2025-12-29T06:50:04.093990Z",
     "shell.execute_reply": "2025-12-29T06:50:04.093227Z",
     "shell.execute_reply.started": "2025-12-29T06:50:00.323390Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.32 s, sys: 1.42 s, total: 4.74 s\n",
      "Wall time: 3.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "c, t, a = h_io.load_data(files=['customers.csv', 'transactions_train.csv', 'articles.csv'])        \n",
    "\n",
    "index_to_id_dict_path = h_fe.reduce_customer_id_memory(c, [t])\n",
    "t[\"week_number\"] = h_fe.day_week_numbers(t[\"t_dat\"])\n",
    "t[\"t_dat\"] = h_fe.day_numbers(t[\"t_dat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get item pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T06:50:04.095747Z",
     "iopub.status.busy": "2025-12-29T06:50:04.095269Z",
     "iopub.status.idle": "2025-12-29T06:50:41.462492Z",
     "shell.execute_reply": "2025-12-29T06:50:41.461843Z",
     "shell.execute_reply.started": "2025-12-29T06:50:04.095708Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating pairs for week number 94\n",
      "Creating pairs for week number 95\n",
      "Creating pairs for week number 96\n",
      "Creating pairs for week number 97\n",
      "Creating pairs for week number 98\n",
      "Creating pairs for week number 99\n",
      "Creating pairs for week number 100\n",
      "Creating pairs for week number 101\n",
      "Creating pairs for week number 102\n",
      "Creating pairs for week number 103\n",
      "Creating pairs for week number 104\n",
      "CPU times: user 28.9 s, sys: 8.42 s, total: 37.3 s\n",
      "Wall time: 37.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Tạo cặp bài viết cho nhiều tuần lịch sử (94–104) với 15 cặp mỗi bài để nâng recall ứng viên\n",
    "pairs_per_item = 15\n",
    "\n",
    "week_number_pairs = {}\n",
    "for week_number in [94,95,96, 97, 98, 99, 100, 101, 102, 103, 104]:\n",
    "    print(f\"Creating pairs for week number {week_number}\")\n",
    "    week_number_pairs[week_number] = h_pairs.create_pairs(\n",
    "        t, week_number, pairs_per_item, verbose=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main retrieval/features function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T06:50:41.463740Z",
     "iopub.status.busy": "2025-12-29T06:50:41.463478Z",
     "iopub.status.idle": "2025-12-29T06:50:41.484443Z",
     "shell.execute_reply": "2025-12-29T06:50:41.483758Z",
     "shell.execute_reply.started": "2025-12-29T06:50:41.463717Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_candidates_with_features_df(t, c, a, customer_batch=None, **kwargs):\n",
    "    # Tách dữ liệu theo tuần label: features dùng các tuần trước, label là tuần đích\n",
    "    features_df, label_df = h_cv.feature_label_split(\n",
    "        t, kwargs[\"label_week\"], kwargs[\"feature_periods\"]\n",
    "    )\n",
    "    # Chuẩn hóa thời gian về “cách đây bao nhiêu ngày/tuần”\n",
    "    features_df[\"t_dat\"] = h_fe.how_many_ago(features_df[\"t_dat\"])\n",
    "    features_df[\"week_number\"] = h_fe.how_many_ago(features_df[\"week_number\"])\n",
    "\n",
    "    article_pairs_df = week_number_pairs[kwargs[\"label_week\"] - 1]\n",
    "\n",
    "    # Xác định tập khách hàng cần xử lý (full/batch/label)\n",
    "    if len(label_df) > 0:\n",
    "        customers = label_df[\"customer_id\"].unique()\n",
    "    elif customer_batch is not None:\n",
    "        customers = customer_batch\n",
    "    else:\n",
    "        customers = None\n",
    "\n",
    "    # ----- Ứng viên từ nhiều nguồn và đặc trưng rule -----\n",
    "    features_db = {}\n",
    "    recent_customer_cand, features_db[\"customer_article\"] = h_can.create_recent_customer_candidates(\n",
    "        features_df, kwargs[\"ca_num_weeks\"], customers=customers\n",
    "    )\n",
    "    (\n",
    "        cust_last_week_cand,\n",
    "        cust_last_week_pair_cand,\n",
    "        features_db[\"clw\"],\n",
    "        features_db[\"clw_pairs\"],\n",
    "    ) = h_can.create_last_customer_weeks_and_pairs(\n",
    "        features_df, article_pairs_df, kwargs[\"clw_num_weeks\"], kwargs[\"clw_num_pair_weeks\"], customers=customers\n",
    "    )\n",
    "    popular_can, features_db[\"popular_articles\"] = h_can.create_popular_article_cand(\n",
    "        features_df, c, a, kwargs[\"pa_num_weeks\"], kwargs[\"hier_col\"],\n",
    "        num_candidates=kwargs[\"num_recent_candidates\"],\n",
    "        num_articles=kwargs[\"num_recent_articles\"],\n",
    "        customers=customers,\n",
    "    )\n",
    "    (age_bucket_can, _, age_bucket_pair_features) = h_can.create_age_bucket_candidates(\n",
    "        features_df, c, kwargs[\"num_age_buckets\"], articles=kwargs[\"num_recent_articles\"], customers=customers\n",
    "    )\n",
    "    features_db[\"age_bucket\"] = age_bucket_pair_features\n",
    "\n",
    "    # NEW: ứng viên random walk\n",
    "    random_walk_cand, features_db[\"f_random_walk\"] = h_can.create_random_walk_candidates(\n",
    "        features_df,\n",
    "        article_pairs_df,\n",
    "        seed_weeks=kwargs[\"gd_seed_weeks\"],\n",
    "        seed_articles=kwargs[\"gd_seed_articles\"],\n",
    "        num_steps=kwargs[\"gd_steps\"],\n",
    "        restart_prob=kwargs[\"gd_restart_prob\"],\n",
    "        topk=kwargs[\"gd_topk\"],\n",
    "        weight_col=kwargs[\"gd_weight_col\"],\n",
    "        recency_weight=kwargs[\"gd_recency_weight\"],\n",
    "        exclude_seed_items=kwargs[\"gd_exclude_seed\"],\n",
    "        customers=customers,\n",
    "    )\n",
    "\n",
    "    # Gom rule-score từ từng nguồn\n",
    "    def build_rule_part(cand_df, feature_tuple, score_col, rule_name):\n",
    "        feature_df = feature_tuple[1].reset_index()[[\"customer_id\", \"article_id\", score_col]]\n",
    "        tmp = cand_df.merge(feature_df, on=[\"customer_id\", \"article_id\"], how=\"left\")\n",
    "        tmp = tmp.rename(columns={score_col: \"rule_score\"})\n",
    "        tmp[\"rule_score\"] = tmp[\"rule_score\"].fillna(-1)\n",
    "        tmp[\"rule\"] = rule_name\n",
    "        return tmp[[\"customer_id\", \"article_id\", \"rule\", \"rule_score\"]]\n",
    "\n",
    "    rule_parts = [\n",
    "        build_rule_part(recent_customer_cand, features_db[\"customer_article\"], \"ca_purchase_count\", \"recent\"),\n",
    "        build_rule_part(cust_last_week_cand, features_db[\"clw\"], \"ca_count\", \"last_weeks\"),\n",
    "        build_rule_part(cust_last_week_pair_cand, features_db[\"clw_pairs\"], \"pair_lift\", \"pairs\"),\n",
    "        build_rule_part(age_bucket_can, features_db[\"age_bucket\"], \"article_bucket_count\", \"age_bucket\"),\n",
    "    ]\n",
    "    # rule popular\n",
    "    pop_feature_df = features_db[\"popular_articles\"][1].reset_index()[[\"article_id\", \"recent_popularity_counts\"]]\n",
    "    pop_rule = popular_can.merge(pop_feature_df, on=\"article_id\", how=\"left\")\n",
    "    pop_rule = pop_rule.rename(columns={\"recent_popularity_counts\": \"rule_score\"})\n",
    "    pop_rule[\"rule_score\"] = pop_rule[\"rule_score\"].fillna(-1)\n",
    "    pop_rule[\"rule\"] = \"popular\"\n",
    "    rule_parts.append(pop_rule[[\"customer_id\", \"article_id\", \"rule\", \"rule_score\"]])\n",
    "    # rule random_walk\n",
    "    rule_parts.append(\n",
    "        build_rule_part(random_walk_cand, features_db[\"f_random_walk\"], \"rw_score\", \"random_walk\")\n",
    "    )\n",
    "\n",
    "    rule_df = cudf.concat(rule_parts).sort_values(\n",
    "        [\"rule\", \"customer_id\", \"rule_score\"], ascending=[True, True, False]\n",
    "    )\n",
    "    rule_df[\"rank_within_rule\"] = rule_df.groupby([\"rule\", \"customer_id\"]).cumcount()\n",
    "\n",
    "    rule_features_df = (\n",
    "        rule_df.groupby([\"customer_id\", \"article_id\"])\n",
    "        .agg({\"rule\": \"nunique\", \"rule_score\": \"max\", \"rank_within_rule\": \"min\"})\n",
    "        .reset_index()\n",
    "    )\n",
    "    rule_features_df.columns = [\"customer_id\", \"article_id\", \"n_sources\", \"best_rule_score\", \"best_rank_within_rule\"]\n",
    "\n",
    "    # Thêm cờ nguồn\n",
    "    for rule_name in rule_df[\"rule\"].unique().to_pandas():\n",
    "        flag_df = rule_df[rule_df[\"rule\"] == rule_name][[\"customer_id\", \"article_id\"]].drop_duplicates()\n",
    "        flag_df[f\"{rule_name}_flag\"] = 1\n",
    "        rule_features_df = rule_features_df.merge(flag_df, how=\"left\", on=[\"customer_id\", \"article_id\"])\n",
    "        rule_features_df[f\"{rule_name}_flag\"] = rule_features_df[f\"{rule_name}_flag\"].fillna(0).astype(\"int8\")\n",
    "\n",
    "    # Hợp nhất ứng viên (đã thêm random_walk)\n",
    "    cand = cudf.concat([\n",
    "        popular_can,\n",
    "        recent_customer_cand,\n",
    "        cust_last_week_cand,\n",
    "        cust_last_week_pair_cand,\n",
    "        age_bucket_can,\n",
    "        random_walk_cand,\n",
    "    ]).drop_duplicates().sort_values([\"customer_id\", \"article_id\"]).reset_index(drop=True)\n",
    "    del popular_can, recent_customer_cand, cust_last_week_cand, cust_last_week_pair_cand, age_bucket_can, random_walk_cand\n",
    "\n",
    "    cand = h_can.filter_candidates(cand, t, **kwargs)\n",
    "\n",
    "    # ----- Sinh thêm đặc trưng -----\n",
    "    h_fe.create_cust_hier_features(features_df, a, kwargs[\"hier_cols\"], features_db)\n",
    "    h_fe.create_cust_hier_decay_features(features_df, a, kwargs[\"hier_cols\"], features_db,\n",
    "                                         decay_gamma=kwargs.get(\"hier_decay_gamma\", 0.3))\n",
    "    for k, v in list(features_db.items()):\n",
    "        if k.endswith(\"_decay_features\"):\n",
    "            hier = k[len(\"cust_\"):-len(\"_decay_features\")]\n",
    "            cols, df = v\n",
    "            df = df.rename(columns={\"last_seen_category_weeks_ago\": f\"last_seen_{hier}_weeks_ago\"})\n",
    "            features_db[k] = (cols, df)\n",
    "\n",
    "    h_fe.create_price_features(features_df, features_db)\n",
    "    h_fe.create_cust_features(c, features_db)\n",
    "    h_fe.create_article_cust_features(features_df, c, features_db)\n",
    "    h_fe.create_lag_features(features_df, a, kwargs[\"lag_days\"], features_db)\n",
    "    h_fe.create_rebuy_features(features_df, features_db)\n",
    "    h_fe.create_cust_t_features(features_df, a, features_db)\n",
    "    try:\n",
    "        h_fe.create_art_t_features(features_df, a, features_db)\n",
    "    except TypeError:\n",
    "        h_fe.create_art_t_features(features_df, features_db)\n",
    "    del features_df\n",
    "\n",
    "    if customers is not None:\n",
    "        cand = cand[cand[\"customer_id\"].isin(customers)]\n",
    "\n",
    "    if kwargs[\"cv\"]:\n",
    "        ground_truth_candidates = label_df[[\"customer_id\", \"article_id\"]].drop_duplicates()\n",
    "        h_cv.report_candidates(cand, ground_truth_candidates)\n",
    "        del ground_truth_candidates\n",
    "\n",
    "    cand_with_f_df = h_can.add_features_to_candidates(cand, features_db, c, a)\n",
    "    cand_with_f_df = cand_with_f_df.merge(rule_features_df, how=\"left\", on=[\"customer_id\", \"article_id\"])\n",
    "\n",
    "    for article_col in kwargs[\"article_columns\"]:\n",
    "        art_col_map = a.set_index(\"article_id\")[article_col]\n",
    "        cand_with_f_df[article_col] = cand_with_f_df[\"article_id\"].map(art_col_map)\n",
    "\n",
    "    # Fill giá trị rule cho ứng viên mới (có random_walk_flag)\n",
    "    rule_fill = {\n",
    "        \"n_sources\": 0,\n",
    "        \"best_rule_score\": -1,\n",
    "        \"best_rank_within_rule\": 127,\n",
    "        \"recent_flag\": 0,\n",
    "        \"last_weeks_flag\": 0,\n",
    "        \"pairs_flag\": 0,\n",
    "        \"age_bucket_flag\": 0,\n",
    "        \"popular_flag\": 0,\n",
    "        \"random_walk_flag\": 0,\n",
    "    }\n",
    "    cand_with_f_df = cand_with_f_df.fillna(rule_fill)\n",
    "\n",
    "    # Target encode các cột category dựa trên best_rule_score (nếu có)\n",
    "    target_col = \"best_rule_score\" if \"best_rule_score\" in cand_with_f_df.columns else None\n",
    "    for col in cand_with_f_df.columns:\n",
    "        if col in [\"customer_id\", \"article_id\"]:\n",
    "            continue\n",
    "        if str(cand_with_f_df[col].dtype) not in [\"int8\",\"int16\",\"int32\",\"int64\",\"float16\",\"float32\",\"float64\",\"bool\"]:\n",
    "            if target_col:\n",
    "                te = cand_with_f_df.groupby(col)[target_col].mean()\n",
    "                cand_with_f_df[col] = cand_with_f_df[col].map(te).fillna(0).astype(\"float32\")\n",
    "            else:\n",
    "                cand_with_f_df[col] = cand_with_f_df[col].astype(\"category\").cat.codes.astype(\"float32\")\n",
    "\n",
    "    if kwargs[\"selected_features\"] is not None:\n",
    "        cand_with_f_df = cand_with_f_df[[\"customer_id\", \"article_id\"] + kwargs[\"selected_features\"]]\n",
    "\n",
    "    assert len(cand) == len(cand_with_f_df), \"seem to have duplicates in the feature dfs\"\n",
    "    del cand\n",
    "\n",
    "    return cand_with_f_df, label_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T06:50:41.485591Z",
     "iopub.status.busy": "2025-12-29T06:50:41.485323Z",
     "iopub.status.idle": "2025-12-29T06:50:41.502313Z",
     "shell.execute_reply": "2025-12-29T06:50:41.501693Z",
     "shell.execute_reply.started": "2025-12-29T06:50:41.485570Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_model_score(ids_df, preds, truth_df):\n",
    "    predictions = h_modeling.create_predictions(ids_df, preds)\n",
    "    true_labels = h_cv.ground_truth(truth_df).set_index(\"customer_id\")[\"prediction\"]\n",
    "    score = round(h_cv.comp_average_precision(true_labels, predictions),5)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters - one place for all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T06:50:41.504081Z",
     "iopub.status.busy": "2025-12-29T06:50:41.503848Z",
     "iopub.status.idle": "2025-12-29T06:50:41.517538Z",
     "shell.execute_reply": "2025-12-29T06:50:41.516811Z",
     "shell.execute_reply.started": "2025-12-29T06:50:41.504053Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cấu hình chạy CV (đa tuần, tăng ứng viên/estimators + random walk)\n",
    "cv_params = {\n",
    "    \"cv\": True,                     # bật báo cáo recall ứng viên\n",
    "    \"feature_periods\": 105,         # dùng 105 tuần lịch sử cho feature\n",
    "    \"label_week\": 104,              # tuần label mặc định, sẽ bị override bởi cv_weeks\n",
    "    \"index_to_id_dict_path\": index_to_id_dict_path,\n",
    "    \"pairs_file_version\": \"_v3_5_ex\",\n",
    "    \"num_recent_candidates\": 80,    # tăng số ứng viên recent để nâng recall\n",
    "    \"num_recent_articles\": 20,      # tăng bài phổ biến/age bucket\n",
    "    \"hier_col\": \"department_no\",\n",
    "    \"ca_num_weeks\": 3,\n",
    "    \"clw_num_weeks\": 12,\n",
    "    \"clw_num_pair_weeks\": 2,\n",
    "    \"pa_num_weeks\": 2,              # kéo dài phổ biến thêm 2 tuần\n",
    "    \"num_age_buckets\": 4,\n",
    "    \"filter_recent_art_weeks\": 1,\n",
    "    \"filter_num_articles\": None,\n",
    "    \"lag_days\": [1, 3, 7, 14, 28],\n",
    "    \"article_columns\": [\"index_code\"],\n",
    "    \"hier_cols\": [\n",
    "        \"department_no\", \"section_no\", \"index_group_no\", \"index_code\",\n",
    "        \"product_type_no\", \"product_group_name\"\n",
    "    ],\n",
    "    \"hier_decay_gamma\": 0.3,\n",
    "    \"selected_features\": None,\n",
    "    # random walk with restart candidates\n",
    "    \"gd_seed_weeks\": 12,\n",
    "    \"gd_seed_articles\": 12,\n",
    "    \"gd_steps\": 2,\n",
    "    \"gd_restart_prob\": \"adaptive\",\n",
    "    \"gd_topk\": 24,\n",
    "    \"gd_weight_col\": \"customer_count\",\n",
    "    \"gd_recency_weight\": True,\n",
    "    \"gd_exclude_seed\": True,\n",
    "    \"lgbm_params\": {                # tăng capacity model cho CV\n",
    "        \"n_estimators\": 400,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"num_leaves\": 64,\n",
    "        \"feature_fraction\": 0.8,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"bagging_freq\": 1,\n",
    "    },\n",
    "    \"log_evaluation\": 10,\n",
    "    \"early_stopping\": 30,\n",
    "    \"eval_at\": 12,\n",
    "    \"save_model\": True,\n",
    "    \"num_concats\": 5,               # ghép 5 tuần train để tăng dữ liệu\n",
    "}\n",
    "\n",
    "# Cấu hình train/predict submit (n_estimators cao hơn, ensemble 2 model + random walk)\n",
    "sub_params = {\n",
    "    \"cv\": False,\n",
    "    \"feature_periods\": 105,\n",
    "    \"label_week\": 105,\n",
    "    \"index_to_id_dict_path\": index_to_id_dict_path,\n",
    "    \"pairs_file_version\": \"_v3_5_ex\",\n",
    "    \"num_recent_candidates\": 80,\n",
    "    \"num_recent_articles\": 20,\n",
    "    \"hier_col\": \"department_no\",\n",
    "    \"ca_num_weeks\": 3,\n",
    "    \"clw_num_weeks\": 12,\n",
    "    \"clw_num_pair_weeks\": 2,\n",
    "    \"pa_num_weeks\": 2,\n",
    "    \"num_age_buckets\": 4,\n",
    "    \"filter_recent_art_weeks\": 1,\n",
    "    \"filter_num_articles\": None,\n",
    "    \"lag_days\": [1, 3, 7, 14, 28],\n",
    "    \"article_columns\": [\"index_code\"],\n",
    "    \"hier_cols\": [\n",
    "        \"department_no\", \"section_no\", \"index_group_no\", \"index_code\",\n",
    "        \"product_type_no\", \"product_group_name\"\n",
    "    ],\n",
    "    \"hier_decay_gamma\": 0.3,\n",
    "    \"selected_features\": None,\n",
    "    # random walk with restart candidates\n",
    "    \"gd_seed_weeks\": 12,\n",
    "    \"gd_seed_articles\": 12,\n",
    "    \"gd_steps\": 2,\n",
    "    \"gd_restart_prob\": \"adaptive\",\n",
    "    \"gd_topk\": 24,\n",
    "    \"gd_weight_col\": \"customer_count\",\n",
    "    \"gd_recency_weight\": True,\n",
    "    \"gd_exclude_seed\": True,\n",
    "    \"lgbm_params\": {                # nhiều cây hơn cho submit\n",
    "        \"n_estimators\": 500,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"num_leaves\": 64,\n",
    "        \"feature_fraction\": 0.8,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"bagging_freq\": 1,\n",
    "    },\n",
    "    \"log_evaluation\": 10,\n",
    "    \"eval_at\": 12,\n",
    "    \"prediction_models\": [\"model_104\", \"model_105\"],  # ensemble 2 model\n",
    "    \"save_model\": True,\n",
    "    \"num_concats\": 5,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T06:50:41.518618Z",
     "iopub.status.busy": "2025-12-29T06:50:41.518287Z",
     "iopub.status.idle": "2025-12-29T06:50:41.534931Z",
     "shell.execute_reply": "2025-12-29T06:50:41.534209Z",
     "shell.execute_reply.started": "2025-12-29T06:50:41.518597Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cand_features_func = create_candidates_with_features_df\n",
    "scoring_func = calculate_model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T06:50:41.536038Z",
     "iopub.status.busy": "2025-12-29T06:50:41.535773Z",
     "iopub.status.idle": "2025-12-29T07:07:04.049329Z",
     "shell.execute_reply": "2025-12-29T07:07:04.048611Z",
     "shell.execute_reply.started": "2025-12-29T06:50:41.536003Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing training modeling dfs for 103...\n",
      "candidates recall: 11.56% (26,350/227,910)\n",
      "candidates precision: 0.53% (26,350/4,977,704)\n",
      "preparing training modeling dfs for 102...\n",
      "candidates recall: 11.90% (28,338/238,074)\n",
      "candidates precision: 0.55% (28,338/5,146,608)\n",
      "preparing training modeling dfs for 101...\n",
      "candidates recall: 11.28% (28,793/255,172)\n",
      "candidates precision: 0.52% (28,793/5,559,132)\n",
      "preparing training modeling dfs for 100...\n",
      "candidates recall: 10.85% (25,038/230,825)\n",
      "candidates precision: 0.46% (25,038/5,408,462)\n",
      "preparing training modeling dfs for 99...\n",
      "candidates recall: 10.70% (25,377/237,160)\n",
      "candidates precision: 0.47% (25,377/5,448,893)\n",
      "concatenating all weeks together\n",
      "preparing evaluation modeling dfs...\n",
      "candidates recall: 12.66% (27,063/213,728)\n",
      "candidates precision: 0.59% (27,063/4,596,301)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Total groups: 96401, total data: 7944468\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.231590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12922\n",
      "[LightGBM] [Info] Number of data points in the train set: 7944468, number of used features: 74\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Total groups: 18996, total data: 1463293\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[10]\ttrain's map@12: 0.207472\ttrain's ndcg@12: 0.280293\tvalidation's map@12: 0.192341\tvalidation's ndcg@12: 0.262597\n",
      "[20]\ttrain's map@12: 0.213378\ttrain's ndcg@12: 0.287343\tvalidation's map@12: 0.19701\tvalidation's ndcg@12: 0.267653\n",
      "[30]\ttrain's map@12: 0.216268\ttrain's ndcg@12: 0.29085\tvalidation's map@12: 0.199766\tvalidation's ndcg@12: 0.27074\n",
      "[40]\ttrain's map@12: 0.218653\ttrain's ndcg@12: 0.293858\tvalidation's map@12: 0.201119\tvalidation's ndcg@12: 0.272345\n",
      "[50]\ttrain's map@12: 0.221144\ttrain's ndcg@12: 0.296751\tvalidation's map@12: 0.201209\tvalidation's ndcg@12: 0.272845\n",
      "[60]\ttrain's map@12: 0.223867\ttrain's ndcg@12: 0.300092\tvalidation's map@12: 0.202187\tvalidation's ndcg@12: 0.27402\n",
      "[70]\ttrain's map@12: 0.226057\ttrain's ndcg@12: 0.302818\tvalidation's map@12: 0.203532\tvalidation's ndcg@12: 0.275596\n",
      "[80]\ttrain's map@12: 0.228218\ttrain's ndcg@12: 0.305141\tvalidation's map@12: 0.204217\tvalidation's ndcg@12: 0.27696\n",
      "[90]\ttrain's map@12: 0.23023\ttrain's ndcg@12: 0.307591\tvalidation's map@12: 0.205143\tvalidation's ndcg@12: 0.278251\n",
      "[100]\ttrain's map@12: 0.232146\ttrain's ndcg@12: 0.30984\tvalidation's map@12: 0.205749\tvalidation's ndcg@12: 0.27892\n",
      "[110]\ttrain's map@12: 0.234103\ttrain's ndcg@12: 0.312054\tvalidation's map@12: 0.20587\tvalidation's ndcg@12: 0.279316\n",
      "[120]\ttrain's map@12: 0.235865\ttrain's ndcg@12: 0.314035\tvalidation's map@12: 0.206958\tvalidation's ndcg@12: 0.280576\n",
      "[130]\ttrain's map@12: 0.237518\ttrain's ndcg@12: 0.315875\tvalidation's map@12: 0.206628\tvalidation's ndcg@12: 0.280381\n",
      "[140]\ttrain's map@12: 0.238992\ttrain's ndcg@12: 0.317597\tvalidation's map@12: 0.20682\tvalidation's ndcg@12: 0.280208\n",
      "[150]\ttrain's map@12: 0.240638\ttrain's ndcg@12: 0.319396\tvalidation's map@12: 0.207279\tvalidation's ndcg@12: 0.280883\n",
      "[160]\ttrain's map@12: 0.242711\ttrain's ndcg@12: 0.321521\tvalidation's map@12: 0.207739\tvalidation's ndcg@12: 0.281542\n",
      "[170]\ttrain's map@12: 0.244197\ttrain's ndcg@12: 0.323196\tvalidation's map@12: 0.20807\tvalidation's ndcg@12: 0.281591\n",
      "[180]\ttrain's map@12: 0.245858\ttrain's ndcg@12: 0.324935\tvalidation's map@12: 0.208386\tvalidation's ndcg@12: 0.281852\n",
      "[190]\ttrain's map@12: 0.247415\ttrain's ndcg@12: 0.32668\tvalidation's map@12: 0.2088\tvalidation's ndcg@12: 0.282241\n",
      "[200]\ttrain's map@12: 0.248786\ttrain's ndcg@12: 0.328151\tvalidation's map@12: 0.20844\tvalidation's ndcg@12: 0.281921\n",
      "[210]\ttrain's map@12: 0.250264\ttrain's ndcg@12: 0.32974\tvalidation's map@12: 0.208442\tvalidation's ndcg@12: 0.282324\n",
      "[220]\ttrain's map@12: 0.251632\ttrain's ndcg@12: 0.331324\tvalidation's map@12: 0.208488\tvalidation's ndcg@12: 0.282233\n",
      "Early stopping, best iteration is:\n",
      "[192]\ttrain's map@12: 0.247558\ttrain's ndcg@12: 0.326893\tvalidation's map@12: 0.208805\tvalidation's ndcg@12: 0.282314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/../input/handmhelpers/modeling.py:272: FutureWarning: Parameter `output_class` was deprecated in version 25.06 and will be replaced with `is_classifier` in 25.08. Please use `is_classifier` in the future. For now, `output_class` parameter has been automatically converted to `is_classifier`.\n",
      "  model = ForestInference.load(model_path, model_type=\"lightgbm\", output_class=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC 0.7797\n",
      "Train score:  0.07628\n",
      "Eval AUC 0.7396\n",
      "Eval score: 0.03623\n",
      "\n",
      "\n",
      "last_weeks_flag        0\n",
      "pairs_flag             0\n",
      "recent_flag            0\n",
      "random_walk_flag       2\n",
      "age_bucket_flag        3\n",
      "                    ... \n",
      "age                  361\n",
      "rebuy_count_ratio    366\n",
      "art_sales_channel    401\n",
      "newness_days         435\n",
      "last_1_days_count    446\n",
      "Length: 74, dtype: int32\n",
      "Finished cv of week 104 in 0:16:22.499416. Score: 0.03623\n",
      "\n",
      "Finished all 1 cvs in 0:16:22.499414. Average cv score: 0.03623\n",
      "CPU times: user 23min 46s, sys: 31.7 s, total: 24min 18s\n",
      "Wall time: 16min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Chạy cross-validation cho các tuần 102-104 (đa tuần để ổn định hơn so với 1 tuần)\n",
    "cv_weeks = [104]\n",
    "results = h_modeling.run_all_cvs(\n",
    "    t, c, a, cand_features_func, scoring_func,\n",
    "    cv_weeks=cv_weeks, **cv_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T07:07:04.050513Z",
     "iopub.status.busy": "2025-12-29T07:07:04.050270Z",
     "iopub.status.idle": "2025-12-29T07:07:04.055660Z",
     "shell.execute_reply": "2025-12-29T07:07:04.055091Z",
     "shell.execute_reply.started": "2025-12-29T07:07:04.050467Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from cuml.fil import ForestInference as _FI\n",
    "\n",
    "_real_load = _FI.load\n",
    "\n",
    "def _load_compat(*args, output_class=None, is_classifier=None, **kwargs):\n",
    "    # helper cũ truyền output_class -> map sang is_classifier\n",
    "    if is_classifier is None and output_class is not None:\n",
    "        is_classifier = output_class\n",
    "    return _real_load(*args, is_classifier=is_classifier, **kwargs)\n",
    "\n",
    "_FI.load = staticmethod(_load_compat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T07:07:04.056894Z",
     "iopub.status.busy": "2025-12-29T07:07:04.056571Z",
     "iopub.status.idle": "2025-12-29T07:07:04.077690Z",
     "shell.execute_reply": "2025-12-29T07:07:04.076888Z",
     "shell.execute_reply.started": "2025-12-29T07:07:04.056862Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=r\".*Parameter `output_class` was deprecated.*\",\n",
    "    category=FutureWarning,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T07:07:04.079025Z",
     "iopub.status.busy": "2025-12-29T07:07:04.078712Z",
     "iopub.status.idle": "2025-12-29T07:07:04.092220Z",
     "shell.execute_reply": "2025-12-29T07:07:04.091646Z",
     "shell.execute_reply.started": "2025-12-29T07:07:04.078989Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import handmhelpers.modeling as h_modeling\n",
    "\n",
    "def full_sub_predict_run_small_batches(t, c, a, cand_features_func, batch_splits=8, **kwargs):\n",
    "    # Chia khách hàng thành nhiều batch nhỏ để tránh OOM khi tạo feature/predict\n",
    "    customer_batches = []\n",
    "    n = len(c)\n",
    "    for i in range(batch_splits):\n",
    "        start = i * n // batch_splits\n",
    "        end = (i + 1) * n // batch_splits\n",
    "        customer_batches.append(c[start:end][\"customer_id\"].to_pandas().to_list())\n",
    "\n",
    "    batch_preds = []\n",
    "    for idx, customer_batch in enumerate(customer_batches):\n",
    "        print(f\"generating candidates/features for batch #{idx+1} of {len(customer_batches)}\")\n",
    "        sub_ids_df, sub_X = h_modeling.prepare_prediction_dfs(\n",
    "            t, c, a, cand_features_func, customer_batch=customer_batch, **kwargs\n",
    "        )\n",
    "        print(f\"candidate/features shape of batch: ({sub_X.shape[0]:,}, {sub_X.shape[1]})\")\n",
    "\n",
    "        # Ensemble các model trong prediction_models, trung bình điểm\n",
    "        model_paths = kwargs.get(\"prediction_models\")\n",
    "        model_nums = len(model_paths)\n",
    "        first_model = h_modeling.ForestInference.load(model_paths[0], model_type=\"lightgbm\", output_class=False)\n",
    "        sub_pred = h_modeling.pred_in_batches(first_model, sub_X) / model_nums\n",
    "        del first_model\n",
    "\n",
    "        for mp in model_paths[1:]:\n",
    "            m = h_modeling.ForestInference.load(mp, model_type=\"lightgbm\", output_class=False)\n",
    "            sub_pred += h_modeling.pred_in_batches(m, sub_X) / model_nums\n",
    "            del m\n",
    "\n",
    "        batch_preds.append(h_modeling.create_predictions(sub_ids_df, sub_pred))\n",
    "        del sub_ids_df, sub_X, sub_pred\n",
    "\n",
    "    return cudf.concat(batch_preds)\n",
    "\n",
    "# Ghi đè hàm predict gốc để dùng bản chia batch nhỏ\n",
    "h_modeling.full_sub_predict_run = full_sub_predict_run_small_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T07:07:04.094606Z",
     "iopub.status.busy": "2025-12-29T07:07:04.094349Z",
     "iopub.status.idle": "2025-12-29T07:41:00.483952Z",
     "shell.execute_reply": "2025-12-29T07:41:00.483286Z",
     "shell.execute_reply.started": "2025-12-29T07:07:04.094582Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing training modeling dfs for 104...\n",
      "preparing training modeling dfs for 103...\n",
      "preparing training modeling dfs for 102...\n",
      "preparing training modeling dfs for 101...\n",
      "preparing training modeling dfs for 100...\n",
      "concatenating all weeks together\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Total groups: 98122, total data: 7837277\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.267977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12928\n",
      "[LightGBM] [Info] Number of data points in the train set: 7837277, number of used features: 74\n",
      "[10]\ttrain's map@12: 0.206139\ttrain's ndcg@12: 0.279035\n",
      "[20]\ttrain's map@12: 0.211926\ttrain's ndcg@12: 0.285663\n",
      "[30]\ttrain's map@12: 0.21468\ttrain's ndcg@12: 0.289063\n",
      "[40]\ttrain's map@12: 0.217149\ttrain's ndcg@12: 0.29231\n",
      "[50]\ttrain's map@12: 0.219849\ttrain's ndcg@12: 0.295357\n",
      "[60]\ttrain's map@12: 0.222254\ttrain's ndcg@12: 0.298533\n",
      "[70]\ttrain's map@12: 0.224455\ttrain's ndcg@12: 0.301155\n",
      "[80]\ttrain's map@12: 0.226303\ttrain's ndcg@12: 0.303332\n",
      "[90]\ttrain's map@12: 0.228264\ttrain's ndcg@12: 0.305627\n",
      "[100]\ttrain's map@12: 0.230169\ttrain's ndcg@12: 0.307862\n",
      "[110]\ttrain's map@12: 0.232034\ttrain's ndcg@12: 0.309932\n",
      "[120]\ttrain's map@12: 0.233783\ttrain's ndcg@12: 0.312005\n",
      "[130]\ttrain's map@12: 0.235613\ttrain's ndcg@12: 0.313986\n",
      "[140]\ttrain's map@12: 0.237213\ttrain's ndcg@12: 0.315836\n",
      "[150]\ttrain's map@12: 0.238962\ttrain's ndcg@12: 0.317647\n",
      "[160]\ttrain's map@12: 0.240502\ttrain's ndcg@12: 0.319413\n",
      "[170]\ttrain's map@12: 0.242221\ttrain's ndcg@12: 0.321282\n",
      "[180]\ttrain's map@12: 0.243875\ttrain's ndcg@12: 0.323055\n",
      "[190]\ttrain's map@12: 0.245258\ttrain's ndcg@12: 0.324584\n",
      "[200]\ttrain's map@12: 0.246849\ttrain's ndcg@12: 0.326229\n",
      "[210]\ttrain's map@12: 0.248376\ttrain's ndcg@12: 0.327905\n",
      "[220]\ttrain's map@12: 0.249851\ttrain's ndcg@12: 0.329502\n",
      "[230]\ttrain's map@12: 0.251294\ttrain's ndcg@12: 0.330913\n",
      "[240]\ttrain's map@12: 0.252744\ttrain's ndcg@12: 0.332437\n",
      "[250]\ttrain's map@12: 0.254232\ttrain's ndcg@12: 0.334007\n",
      "[260]\ttrain's map@12: 0.255655\ttrain's ndcg@12: 0.335568\n",
      "[270]\ttrain's map@12: 0.257106\ttrain's ndcg@12: 0.337099\n",
      "[280]\ttrain's map@12: 0.258648\ttrain's ndcg@12: 0.338683\n",
      "[290]\ttrain's map@12: 0.260015\ttrain's ndcg@12: 0.340125\n",
      "[300]\ttrain's map@12: 0.261411\ttrain's ndcg@12: 0.341632\n",
      "[310]\ttrain's map@12: 0.262852\ttrain's ndcg@12: 0.343112\n",
      "[320]\ttrain's map@12: 0.264202\ttrain's ndcg@12: 0.344469\n",
      "[330]\ttrain's map@12: 0.265521\ttrain's ndcg@12: 0.345901\n",
      "[340]\ttrain's map@12: 0.266856\ttrain's ndcg@12: 0.347375\n",
      "[350]\ttrain's map@12: 0.26822\ttrain's ndcg@12: 0.348846\n",
      "[360]\ttrain's map@12: 0.269437\ttrain's ndcg@12: 0.350035\n",
      "[370]\ttrain's map@12: 0.270784\ttrain's ndcg@12: 0.351466\n",
      "[380]\ttrain's map@12: 0.271949\ttrain's ndcg@12: 0.352871\n",
      "[390]\ttrain's map@12: 0.273057\ttrain's ndcg@12: 0.35412\n",
      "[400]\ttrain's map@12: 0.274308\ttrain's ndcg@12: 0.355394\n",
      "[410]\ttrain's map@12: 0.275378\ttrain's ndcg@12: 0.356549\n",
      "[420]\ttrain's map@12: 0.276703\ttrain's ndcg@12: 0.357925\n",
      "[430]\ttrain's map@12: 0.277991\ttrain's ndcg@12: 0.359305\n",
      "[440]\ttrain's map@12: 0.279262\ttrain's ndcg@12: 0.360704\n",
      "[450]\ttrain's map@12: 0.280546\ttrain's ndcg@12: 0.362014\n",
      "[460]\ttrain's map@12: 0.281521\ttrain's ndcg@12: 0.363111\n",
      "[470]\ttrain's map@12: 0.282699\ttrain's ndcg@12: 0.364377\n",
      "[480]\ttrain's map@12: 0.283972\ttrain's ndcg@12: 0.365741\n",
      "[490]\ttrain's map@12: 0.285222\ttrain's ndcg@12: 0.366982\n",
      "[500]\ttrain's map@12: 0.286441\ttrain's ndcg@12: 0.368191\n",
      "Train AUC 0.7914\n",
      "Train score:  0.08237\n",
      "generating candidates/features for batch #1 of 8\n",
      "candidate/features shape of batch: (9,244,594, 74)\n",
      "generating candidates/features for batch #2 of 8\n",
      "candidate/features shape of batch: (9,218,637, 74)\n",
      "generating candidates/features for batch #3 of 8\n",
      "candidate/features shape of batch: (9,228,991, 74)\n",
      "generating candidates/features for batch #4 of 8\n",
      "candidate/features shape of batch: (9,230,745, 74)\n",
      "generating candidates/features for batch #5 of 8\n",
      "candidate/features shape of batch: (9,237,178, 74)\n",
      "generating candidates/features for batch #6 of 8\n",
      "candidate/features shape of batch: (9,230,083, 74)\n",
      "generating candidates/features for batch #7 of 8\n",
      "candidate/features shape of batch: (9,217,395, 74)\n",
      "generating candidates/features for batch #8 of 8\n",
      "candidate/features shape of batch: (9,221,508, 74)\n",
      "CPU times: user 46min 39s, sys: 1min 22s, total: 48min 2s\n",
      "Wall time: 33min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gc.collect()\n",
    "# Train full dữ liệu submit và lưu model theo sub_params\n",
    "h_modeling.full_sub_train_run(t, c, a, cand_features_func, scoring_func, **sub_params)\n",
    "# Predict theo batch nhỏ (batch_splits=8) để tránh OOM, dùng ensemble model_104/model_105\n",
    "predictions = h_modeling.full_sub_predict_run(\n",
    "    t, c, a, cand_features_func, batch_splits=8, **sub_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T07:41:00.485211Z",
     "iopub.status.busy": "2025-12-29T07:41:00.484924Z",
     "iopub.status.idle": "2025-12-29T07:41:36.658972Z",
     "shell.execute_reply": "2025-12-29T07:41:36.658329Z",
     "shell.execute_reply.started": "2025-12-29T07:41:00.485185Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "      <td>0568601043 0779781015 0839332002 0770315020 05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n",
       "      <td>0788575002 0714790020 0448509014 0874110016 09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>0794321007 0794321008 0805000001 0918522001 08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...</td>\n",
       "      <td>0852584001 0861803009 0918292001 0730683050 08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...</td>\n",
       "      <td>0791587001 0791587021 0730683050 0924243001 09...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_id  \\\n",
       "0  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...   \n",
       "1  0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...   \n",
       "2  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   \n",
       "3  00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...   \n",
       "4  00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...   \n",
       "\n",
       "                                          prediction  \n",
       "0  0568601043 0779781015 0839332002 0770315020 05...  \n",
       "1  0788575002 0714790020 0448509014 0874110016 09...  \n",
       "2  0794321007 0794321008 0805000001 0918522001 08...  \n",
       "3  0852584001 0861803009 0918292001 0730683050 08...  \n",
       "4  0791587001 0791587021 0730683050 0924243001 09...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1371980, 2)\n"
     ]
    }
   ],
   "source": [
    "sub = h_sub.create_sub(c[\"customer_id\"], predictions, index_to_id_dict_path)\n",
    "sub.to_csv('dev_submission.csv', index=False)\n",
    "\n",
    "display(sub.head())\n",
    "print(sub.shape)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 3103714,
     "sourceId": 31254,
     "sourceType": "competition"
    },
    {
     "datasetId": 9140518,
     "sourceId": 14327604,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
