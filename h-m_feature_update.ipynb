{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T01:54:06.119095Z",
     "iopub.status.busy": "2025-12-29T01:54:06.118821Z",
     "iopub.status.idle": "2025-12-29T01:54:19.468650Z",
     "shell.execute_reply": "2025-12-29T01:54:19.467835Z",
     "shell.execute_reply.started": "2025-12-29T01:54:06.119068Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sqlalchemy/orm/query.py:195: SyntaxWarning: \"is not\" with 'tuple' literal. Did you mean \"!=\"?\n",
      "  if entities is not ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.35 s, sys: 1.24 s, total: 8.59 s\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "from datetime import datetime\n",
    "import gc\n",
    "import pickle as pkl\n",
    "import shelve\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cudf\n",
    "    \n",
    "sys.path.append(\"../input/\")\n",
    "from handmhelpers import io as h_io, sub as h_sub, cv as h_cv, fe as h_fe\n",
    "from handmhelpers import modeling as h_modeling, candidates as h_can, pairs as h_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and convert data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T01:54:21.538163Z",
     "iopub.status.busy": "2025-12-29T01:54:21.537657Z",
     "iopub.status.idle": "2025-12-29T01:54:21.543271Z",
     "shell.execute_reply": "2025-12-29T01:54:21.542706Z",
     "shell.execute_reply.started": "2025-12-29T01:54:21.538134Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import cudf\n",
    "import numpy as np\n",
    "\n",
    "def patched_day_week_numbers(dates: cudf.Series):\n",
    "    pd_dates = cudf.to_datetime(dates)\n",
    "    unique_dates = cudf.Series(pd_dates.unique())\n",
    "    numbered_days = unique_dates - unique_dates.min() + timedelta(1)\n",
    "    numbered_days = numbered_days.dt.days\n",
    "    extra_days = numbered_days.max() % 7\n",
    "    numbered_days -= extra_days\n",
    "    day_weeks = (numbered_days + 6) // 7  # không dùng applymap\n",
    "    day_weeks_map = cudf.DataFrame({\"day_weeks\": day_weeks, \"unique_dates\": unique_dates}).set_index(\"unique_dates\")[\"day_weeks\"]\n",
    "    all_day_weeks = pd_dates.map(day_weeks_map).astype(\"int8\")\n",
    "    return all_day_weeks\n",
    "\n",
    "import handmhelpers.fe as h_fe\n",
    "h_fe.day_week_numbers = patched_day_week_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T01:54:23.859846Z",
     "iopub.status.busy": "2025-12-29T01:54:23.859540Z",
     "iopub.status.idle": "2025-12-29T01:54:34.065911Z",
     "shell.execute_reply": "2025-12-29T01:54:34.065127Z",
     "shell.execute_reply.started": "2025-12-29T01:54:23.859820Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.03 s, sys: 2.43 s, total: 5.46 s\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "c, t, a = h_io.load_data(files=['customers.csv', 'transactions_train.csv', 'articles.csv'])        \n",
    "\n",
    "index_to_id_dict_path = h_fe.reduce_customer_id_memory(c, [t])\n",
    "t[\"week_number\"] = h_fe.day_week_numbers(t[\"t_dat\"])\n",
    "t[\"t_dat\"] = h_fe.day_numbers(t[\"t_dat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get item pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T01:54:34.067510Z",
     "iopub.status.busy": "2025-12-29T01:54:34.067247Z",
     "iopub.status.idle": "2025-12-29T01:55:13.622378Z",
     "shell.execute_reply": "2025-12-29T01:55:13.621586Z",
     "shell.execute_reply.started": "2025-12-29T01:54:34.067463Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating pairs for week number 94\n",
      "Creating pairs for week number 95\n",
      "Creating pairs for week number 96\n",
      "Creating pairs for week number 97\n",
      "Creating pairs for week number 98\n",
      "Creating pairs for week number 99\n",
      "Creating pairs for week number 100\n",
      "Creating pairs for week number 101\n",
      "Creating pairs for week number 102\n",
      "Creating pairs for week number 103\n",
      "Creating pairs for week number 104\n",
      "CPU times: user 32.4 s, sys: 5.99 s, total: 38.4 s\n",
      "Wall time: 39.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Tạo cặp bài viết cho nhiều tuần lịch sử (94–104) với 15 cặp mỗi bài để nâng recall ứng viên\n",
    "pairs_per_item = 15\n",
    "\n",
    "week_number_pairs = {}\n",
    "for week_number in [94,95,96, 97, 98, 99, 100, 101, 102, 103, 104]:\n",
    "    print(f\"Creating pairs for week number {week_number}\")\n",
    "    week_number_pairs[week_number] = h_pairs.create_pairs(\n",
    "        t, week_number, pairs_per_item, verbose=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main retrieval/features function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T01:59:30.308816Z",
     "iopub.status.busy": "2025-12-29T01:59:30.308354Z",
     "iopub.status.idle": "2025-12-29T01:59:30.335219Z",
     "shell.execute_reply": "2025-12-29T01:59:30.334554Z",
     "shell.execute_reply.started": "2025-12-29T01:59:30.308788Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_candidates_with_features_df(t, c, a, customer_batch=None, **kwargs):\n",
    "    # Tách dữ liệu theo tuần label: features dùng các tuần trước, label là tuần đích\n",
    "    features_df, label_df = h_cv.feature_label_split(\n",
    "        t, kwargs[\"label_week\"], kwargs[\"feature_periods\"]\n",
    "    )\n",
    "    # Đưa thời gian về dạng “cách đây bao nhiêu ngày/tuần” để model không lộ lịch tuyệt đối\n",
    "    features_df[\"t_dat\"] = h_fe.how_many_ago(features_df[\"t_dat\"])\n",
    "    features_df[\"week_number\"] = h_fe.how_many_ago(features_df[\"week_number\"])\n",
    "\n",
    "    # Lấy bảng cặp bài viết của tuần ngay trước tuần label\n",
    "    article_pairs_df = week_number_pairs[kwargs[\"label_week\"] - 1]\n",
    "\n",
    "    # Xác định tập khách hàng cần xử lý (full, batch, hoặc chỉ khách có label)\n",
    "    if len(label_df) > 0:\n",
    "        customers = label_df[\"customer_id\"].unique()\n",
    "    elif customer_batch is not None:\n",
    "        customers = customer_batch\n",
    "    else:\n",
    "        customers = None\n",
    "\n",
    "    # ----- Tạo ứng viên từ nhiều nguồn và lưu đặc trưng rule -----\n",
    "    features_db = {}\n",
    "\n",
    "    # NEW: ứng viên mua gần đây (theo ca_num_weeks), dùng cho recall ngắn hạn\n",
    "    recent_customer_cand, features_db[\"customer_article\"] = h_can.create_recent_customer_candidates(\n",
    "        features_df, kwargs[\"ca_num_weeks\"], customers=customers\n",
    "    )\n",
    "\n",
    "    # NEW: ứng viên tuần gần nhất + cặp lift theo tuần (clw_num_weeks, clw_num_pair_weeks)\n",
    "    (\n",
    "        cust_last_week_cand,\n",
    "        cust_last_week_pair_cand,\n",
    "        features_db[\"clw\"],\n",
    "        features_db[\"clw_pairs\"],\n",
    "    ) = h_can.create_last_customer_weeks_and_pairs(\n",
    "        features_df, article_pairs_df, kwargs[\"clw_num_weeks\"], kwargs[\"clw_num_pair_weeks\"], customers=customers\n",
    "    )\n",
    "\n",
    "    # Bài phổ biến theo hierarchy (department/index…), số lượng điều khiển bằng num_recent_candidates/articles\n",
    "    _, features_db[\"popular_articles\"] = h_can.create_popular_article_cand(\n",
    "        features_df, c, a, kwargs[\"pa_num_weeks\"], kwargs[\"hier_col\"],\n",
    "        num_candidates=kwargs[\"num_recent_candidates\"],\n",
    "        num_articles=kwargs[\"num_recent_articles\"],\n",
    "        customers=customers,\n",
    "    )\n",
    "\n",
    "    # NEW: ứng viên theo bucket tuổi, thêm đặc trưng cặp theo bucket\n",
    "    (\n",
    "        age_bucket_can,\n",
    "        age_bucket_cust_features,\n",
    "        age_bucket_pair_features,\n",
    "    ) = h_can.create_age_bucket_candidates(\n",
    "        features_df, c, kwargs[\"num_age_buckets\"], articles=kwargs[\"num_recent_articles\"], customers=customers\n",
    "    )\n",
    "    features_db[\"age_bucket\"] = age_bucket_pair_features\n",
    "\n",
    "    # Gom rule-score từ từng nguồn ứng viên thành bảng rule_features_df\n",
    "    def build_rule_part(cand_df, feature_tuple, score_col, rule_name):\n",
    "        feature_df = feature_tuple[1].reset_index()[[\"customer_id\", \"article_id\", score_col]]\n",
    "        tmp = cand_df.merge(feature_df, on=[\"customer_id\", \"article_id\"], how=\"left\")\n",
    "        tmp = tmp.rename(columns={score_col: \"rule_score\"})\n",
    "        tmp[\"rule_score\"] = tmp[\"rule_score\"].fillna(-1)\n",
    "        tmp[\"rule\"] = rule_name\n",
    "        return tmp[[\"customer_id\", \"article_id\", \"rule\", \"rule_score\"]]\n",
    "\n",
    "    rule_parts = [\n",
    "        build_rule_part(recent_customer_cand, features_db[\"customer_article\"], \"ca_purchase_count\", \"recent\"),\n",
    "        build_rule_part(cust_last_week_cand, features_db[\"clw\"], \"ca_count\", \"last_weeks\"),\n",
    "        build_rule_part(cust_last_week_pair_cand, features_db[\"clw_pairs\"], \"pair_lift\", \"pairs\"),\n",
    "        build_rule_part(age_bucket_can, features_db[\"age_bucket\"], \"article_bucket_count\", \"age_bucket\"),\n",
    "    ]\n",
    "    rule_df = cudf.concat(rule_parts).sort_values(\n",
    "        [\"rule\", \"customer_id\", \"rule_score\"], ascending=[True, True, False]\n",
    "    )\n",
    "    rule_df[\"rank_within_rule\"] = rule_df.groupby([\"rule\", \"customer_id\"]).cumcount()\n",
    "\n",
    "    rule_features_df = (\n",
    "        rule_df.groupby([\"customer_id\", \"article_id\"])\n",
    "        .agg({\"rule\": \"nunique\", \"rule_score\": \"max\", \"rank_within_rule\": \"min\"})\n",
    "        .reset_index()\n",
    "    )\n",
    "    rule_features_df.columns = [\"customer_id\", \"article_id\", \"n_sources\", \"best_rule_score\", \"best_rank_within_rule\"]\n",
    "\n",
    "    # Thêm cờ nguồn (recent/last_weeks/pairs/age_bucket)\n",
    "    for rule_name in rule_df[\"rule\"].unique().to_pandas():\n",
    "        flag_df = rule_df[rule_df[\"rule\"] == rule_name][[\"customer_id\", \"article_id\"]].drop_duplicates()\n",
    "        flag_df[f\"{rule_name}_flag\"] = 1\n",
    "        rule_features_df = rule_features_df.merge(flag_df, how=\"left\", on=[\"customer_id\", \"article_id\"])\n",
    "        rule_features_df[f\"{rule_name}_flag\"] = rule_features_df[f\"{rule_name}_flag\"].fillna(0).astype(\"int8\")\n",
    "\n",
    "    # Hợp nhất các nguồn ứng viên và lọc trùng\n",
    "    cand = cudf.concat([recent_customer_cand, cust_last_week_cand, cust_last_week_pair_cand, age_bucket_can])\\\n",
    "              .drop_duplicates()\\\n",
    "              .sort_values([\"customer_id\", \"article_id\"])\\\n",
    "              .reset_index(drop=True)\n",
    "    del recent_customer_cand, cust_last_week_cand, cust_last_week_pair_cand, age_bucket_can\n",
    "\n",
    "    cand = h_can.filter_candidates(cand, t, **kwargs)\n",
    "\n",
    "    # ----- Sinh thêm đặc trưng hành vi/giá/recency/lag -----\n",
    "    h_fe.create_cust_hier_features(features_df, a, kwargs[\"hier_cols\"], features_db)\n",
    "    h_fe.create_cust_hier_decay_features(features_df, a, kwargs[\"hier_cols\"], features_db,\n",
    "                                         decay_gamma=kwargs.get(\"hier_decay_gamma\", 0.3))\n",
    "    # NEW: đổi tên cột decay để nhất quán “last_seen_<hier>_weeks_ago”\n",
    "    for k, v in list(features_db.items()):\n",
    "        if k.endswith(\"_decay_features\"):\n",
    "            hier = k[len(\"cust_\"):-len(\"_decay_features\")]\n",
    "            cols, df = v\n",
    "            df = df.rename(columns={\"last_seen_category_weeks_ago\": f\"last_seen_{hier}_weeks_ago\"})\n",
    "            features_db[k] = (cols, df)\n",
    "\n",
    "    h_fe.create_price_features(features_df, features_db)\n",
    "    h_fe.create_cust_features(c, features_db)\n",
    "    h_fe.create_article_cust_features(features_df, c, features_db)\n",
    "    h_fe.create_lag_features(features_df, a, kwargs[\"lag_days\"], features_db)\n",
    "    h_fe.create_rebuy_features(features_df, features_db)\n",
    "    h_fe.create_cust_t_features(features_df, a, features_db)\n",
    "    h_fe.create_art_t_features(features_df, a, features_db)\n",
    "    del features_df\n",
    "\n",
    "    # Giới hạn lại tập ứng viên nếu chỉ chạy trên subset khách\n",
    "    if customers is not None:\n",
    "        cand = cand[cand[\"customer_id\"].isin(customers)]\n",
    "\n",
    "    # Báo cáo recall/precision ứng viên trên CV để theo dõi trần mô hình\n",
    "    if kwargs[\"cv\"]:\n",
    "        ground_truth_candidates = label_df[[\"customer_id\", \"article_id\"]].drop_duplicates()\n",
    "        h_cv.report_candidates(cand, ground_truth_candidates)\n",
    "        del ground_truth_candidates\n",
    "\n",
    "    # Gắn đặc trưng vào ứng viên\n",
    "    cand_with_f_df = h_can.add_features_to_candidates(cand, features_db, c, a)\n",
    "    cand_with_f_df = cand_with_f_df.merge(rule_features_df, how=\"left\", on=[\"customer_id\", \"article_id\"])\n",
    "\n",
    "    # Thêm cột article thủ công (không dùng shelve được)\n",
    "    for article_col in kwargs[\"article_columns\"]:\n",
    "        art_col_map = a.set_index(\"article_id\")[article_col]\n",
    "        cand_with_f_df[article_col] = cand_with_f_df[\"article_id\"].map(art_col_map)\n",
    "\n",
    "    # NEW: target encode các cột category dựa trên best_rule_score (nếu có), tránh mã thứ tự tùy ý\n",
    "    target_col = \"best_rule_score\" if \"best_rule_score\" in cand_with_f_df.columns else None\n",
    "    for col in cand_with_f_df.columns:\n",
    "        if col in [\"customer_id\", \"article_id\"]:\n",
    "            continue\n",
    "        if str(cand_with_f_df[col].dtype) not in [\"int8\",\"int16\",\"int32\",\"int64\",\"float16\",\"float32\",\"float64\",\"bool\"]:\n",
    "            if target_col:\n",
    "                te = cand_with_f_df.groupby(col)[target_col].mean()\n",
    "                cand_with_f_df[col] = cand_with_f_df[col].map(te).fillna(0).astype(\"float32\")\n",
    "            else:\n",
    "                cand_with_f_df[col] = cand_with_f_df[col].astype(\"category\").cat.codes.astype(\"float32\")\n",
    "\n",
    "    # Giữ subset đặc trưng nếu được chọn sẵn\n",
    "    if kwargs[\"selected_features\"] is not None:\n",
    "        cand_with_f_df = cand_with_f_df[[\"customer_id\", \"article_id\"] + kwargs[\"selected_features\"]]\n",
    "\n",
    "    assert len(cand) == len(cand_with_f_df), \"seem to have duplicates in the feature dfs\"\n",
    "    del cand\n",
    "\n",
    "    return cand_with_f_df, label_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T01:59:32.092477Z",
     "iopub.status.busy": "2025-12-29T01:59:32.092196Z",
     "iopub.status.idle": "2025-12-29T01:59:32.096629Z",
     "shell.execute_reply": "2025-12-29T01:59:32.095950Z",
     "shell.execute_reply.started": "2025-12-29T01:59:32.092453Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_model_score(ids_df, preds, truth_df):\n",
    "    predictions = h_modeling.create_predictions(ids_df, preds)\n",
    "    true_labels = h_cv.ground_truth(truth_df).set_index(\"customer_id\")[\"prediction\"]\n",
    "    score = round(h_cv.comp_average_precision(true_labels, predictions),5)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters - one place for all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T01:59:33.491552Z",
     "iopub.status.busy": "2025-12-29T01:59:33.491028Z",
     "iopub.status.idle": "2025-12-29T01:59:33.498387Z",
     "shell.execute_reply": "2025-12-29T01:59:33.497682Z",
     "shell.execute_reply.started": "2025-12-29T01:59:33.491526Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cấu hình chạy CV (đa tuần, tăng ứng viên/estimators)\n",
    "cv_params = {\n",
    "    \"cv\": True,                     # bật báo cáo recall ứng viên\n",
    "    \"feature_periods\": 105,         # dùng 105 tuần lịch sử cho feature\n",
    "    \"label_week\": 104,              # tuần label mặc định, sẽ bị override bởi cv_weeks\n",
    "    \"index_to_id_dict_path\": index_to_id_dict_path,\n",
    "    \"pairs_file_version\": \"_v3_5_ex\",\n",
    "    \"num_recent_candidates\": 80,    # NEW: tăng số ứng viên recent để nâng recall\n",
    "    \"num_recent_articles\": 20,      # NEW: tăng bài phổ biến/age bucket\n",
    "    \"hier_col\": \"department_no\",\n",
    "    \"ca_num_weeks\": 3,\n",
    "    \"clw_num_weeks\": 12,\n",
    "    \"clw_num_pair_weeks\": 2,\n",
    "    \"pa_num_weeks\": 2,              # NEW: kéo dài phổ biến thêm 2 tuần\n",
    "    \"num_age_buckets\": 4,\n",
    "    \"filter_recent_art_weeks\": 1,\n",
    "    \"filter_num_articles\": None,\n",
    "    \"lag_days\": [1, 3, 7, 14, 28],\n",
    "    \"article_columns\": [\"index_code\"],\n",
    "    \"hier_cols\": [\n",
    "        \"department_no\", \"section_no\", \"index_group_no\", \"index_code\",\n",
    "        \"product_type_no\", \"product_group_name\"\n",
    "    ],\n",
    "    \"hier_decay_gamma\": 0.3,\n",
    "    \"selected_features\": None,\n",
    "    \"lgbm_params\": {                # NEW: tăng capacity model cho CV\n",
    "        \"n_estimators\": 400,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"num_leaves\": 64,\n",
    "        \"feature_fraction\": 0.8,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"bagging_freq\": 1,\n",
    "    },\n",
    "    \"log_evaluation\": 10,\n",
    "    \"early_stopping\": 30,\n",
    "    \"eval_at\": 12,\n",
    "    \"save_model\": True,\n",
    "    \"num_concats\": 5,               # ghép 5 tuần train để tăng dữ liệu\n",
    "}\n",
    "\n",
    "# Cấu hình train/predict submit (tương tự CV nhưng n_estimators cao hơn, predict ensembe 2 model)\n",
    "sub_params = {\n",
    "    \"cv\": False,\n",
    "    \"feature_periods\": 105,\n",
    "    \"label_week\": 105,\n",
    "    \"index_to_id_dict_path\": index_to_id_dict_path,\n",
    "    \"pairs_file_version\": \"_v3_5_ex\",\n",
    "    \"num_recent_candidates\": 80,\n",
    "    \"num_recent_articles\": 20,\n",
    "    \"hier_col\": \"department_no\",\n",
    "    \"ca_num_weeks\": 3,\n",
    "    \"clw_num_weeks\": 12,\n",
    "    \"clw_num_pair_weeks\": 2,\n",
    "    \"pa_num_weeks\": 2,\n",
    "    \"num_age_buckets\": 4,\n",
    "    \"filter_recent_art_weeks\": 1,\n",
    "    \"filter_num_articles\": None,\n",
    "    \"lag_days\": [1, 3, 7, 14, 28],\n",
    "    \"article_columns\": [\"index_code\"],\n",
    "    \"hier_cols\": [\n",
    "        \"department_no\", \"section_no\", \"index_group_no\", \"index_code\",\n",
    "        \"product_type_no\", \"product_group_name\"\n",
    "    ],\n",
    "    \"hier_decay_gamma\": 0.3,\n",
    "    \"selected_features\": None,\n",
    "    \"lgbm_params\": {                # NEW: nhiều cây hơn cho submit\n",
    "        \"n_estimators\": 500,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"num_leaves\": 64,\n",
    "        \"feature_fraction\": 0.8,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"bagging_freq\": 1,\n",
    "    },\n",
    "    \"log_evaluation\": 10,\n",
    "    \"eval_at\": 12,\n",
    "    \"prediction_models\": [\"model_104\", \"model_105\"],  # ensembe 2 model\n",
    "    \"save_model\": True,\n",
    "    \"num_concats\": 5,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T01:59:35.840417Z",
     "iopub.status.busy": "2025-12-29T01:59:35.839855Z",
     "iopub.status.idle": "2025-12-29T01:59:35.843588Z",
     "shell.execute_reply": "2025-12-29T01:59:35.842819Z",
     "shell.execute_reply.started": "2025-12-29T01:59:35.840390Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cand_features_func = create_candidates_with_features_df\n",
    "scoring_func = calculate_model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T01:59:37.431003Z",
     "iopub.status.busy": "2025-12-29T01:59:37.430451Z",
     "iopub.status.idle": "2025-12-29T02:21:38.460846Z",
     "shell.execute_reply": "2025-12-29T02:21:38.460137Z",
     "shell.execute_reply.started": "2025-12-29T01:59:37.430974Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing training modeling dfs for 101...\n",
      "candidates recall: 9.63% (24,570/255,172)\n",
      "candidates precision: 0.58% (24,570/4,270,526)\n",
      "preparing training modeling dfs for 100...\n",
      "candidates recall: 9.63% (22,224/230,825)\n",
      "candidates precision: 0.55% (22,224/4,039,298)\n",
      "preparing training modeling dfs for 99...\n",
      "candidates recall: 9.35% (22,171/237,160)\n",
      "candidates precision: 0.53% (22,171/4,209,718)\n",
      "preparing training modeling dfs for 98...\n",
      "candidates recall: 8.48% (22,010/259,512)\n",
      "candidates precision: 0.50% (22,010/4,395,378)\n",
      "preparing training modeling dfs for 97...\n",
      "candidates recall: 7.82% (22,502/287,700)\n",
      "candidates precision: 0.48% (22,502/4,640,200)\n",
      "concatenating all weeks together\n",
      "preparing evaluation modeling dfs...\n",
      "candidates recall: 10.32% (24,561/238,074)\n",
      "candidates precision: 0.61% (24,561/4,033,310)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Total groups: 82212, total data: 5960226\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.849291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12626\n",
      "[LightGBM] [Info] Number of data points in the train set: 5960226, number of used features: 71\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Total groups: 18125, total data: 1194294\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[10]\ttrain's map@12: 0.233744\ttrain's ndcg@12: 0.313674\tvalidation's map@12: 0.223485\tvalidation's ndcg@12: 0.302401\n",
      "[20]\ttrain's map@12: 0.23924\ttrain's ndcg@12: 0.31994\tvalidation's map@12: 0.224602\tvalidation's ndcg@12: 0.304763\n",
      "[30]\ttrain's map@12: 0.242779\ttrain's ndcg@12: 0.324437\tvalidation's map@12: 0.226254\tvalidation's ndcg@12: 0.30651\n",
      "[40]\ttrain's map@12: 0.246061\ttrain's ndcg@12: 0.328013\tvalidation's map@12: 0.228977\tvalidation's ndcg@12: 0.30927\n",
      "[50]\ttrain's map@12: 0.249313\ttrain's ndcg@12: 0.331945\tvalidation's map@12: 0.230616\tvalidation's ndcg@12: 0.311255\n",
      "[60]\ttrain's map@12: 0.251928\ttrain's ndcg@12: 0.335127\tvalidation's map@12: 0.230352\tvalidation's ndcg@12: 0.311489\n",
      "[70]\ttrain's map@12: 0.253939\ttrain's ndcg@12: 0.337531\tvalidation's map@12: 0.231634\tvalidation's ndcg@12: 0.312551\n",
      "[80]\ttrain's map@12: 0.256595\ttrain's ndcg@12: 0.340413\tvalidation's map@12: 0.232148\tvalidation's ndcg@12: 0.312643\n",
      "[90]\ttrain's map@12: 0.259036\ttrain's ndcg@12: 0.343104\tvalidation's map@12: 0.233042\tvalidation's ndcg@12: 0.314087\n",
      "[100]\ttrain's map@12: 0.261541\ttrain's ndcg@12: 0.345865\tvalidation's map@12: 0.233956\tvalidation's ndcg@12: 0.31515\n",
      "[110]\ttrain's map@12: 0.263803\ttrain's ndcg@12: 0.348374\tvalidation's map@12: 0.23469\tvalidation's ndcg@12: 0.315844\n",
      "[120]\ttrain's map@12: 0.265603\ttrain's ndcg@12: 0.350232\tvalidation's map@12: 0.23465\tvalidation's ndcg@12: 0.315991\n",
      "[130]\ttrain's map@12: 0.267702\ttrain's ndcg@12: 0.352473\tvalidation's map@12: 0.234862\tvalidation's ndcg@12: 0.31627\n",
      "[140]\ttrain's map@12: 0.269704\ttrain's ndcg@12: 0.354499\tvalidation's map@12: 0.235452\tvalidation's ndcg@12: 0.316594\n",
      "[150]\ttrain's map@12: 0.271571\ttrain's ndcg@12: 0.356473\tvalidation's map@12: 0.235915\tvalidation's ndcg@12: 0.31717\n",
      "[160]\ttrain's map@12: 0.273247\ttrain's ndcg@12: 0.358233\tvalidation's map@12: 0.23606\tvalidation's ndcg@12: 0.317388\n",
      "[170]\ttrain's map@12: 0.275109\ttrain's ndcg@12: 0.360142\tvalidation's map@12: 0.236593\tvalidation's ndcg@12: 0.31787\n",
      "[180]\ttrain's map@12: 0.277095\ttrain's ndcg@12: 0.36223\tvalidation's map@12: 0.236681\tvalidation's ndcg@12: 0.317952\n",
      "[190]\ttrain's map@12: 0.278898\ttrain's ndcg@12: 0.364227\tvalidation's map@12: 0.236212\tvalidation's ndcg@12: 0.317501\n",
      "[200]\ttrain's map@12: 0.280716\ttrain's ndcg@12: 0.366065\tvalidation's map@12: 0.236783\tvalidation's ndcg@12: 0.318311\n",
      "[210]\ttrain's map@12: 0.28271\ttrain's ndcg@12: 0.368037\tvalidation's map@12: 0.237045\tvalidation's ndcg@12: 0.318732\n",
      "[220]\ttrain's map@12: 0.284596\ttrain's ndcg@12: 0.369855\tvalidation's map@12: 0.236837\tvalidation's ndcg@12: 0.318741\n",
      "[230]\ttrain's map@12: 0.286498\ttrain's ndcg@12: 0.371805\tvalidation's map@12: 0.236523\tvalidation's ndcg@12: 0.31828\n",
      "[240]\ttrain's map@12: 0.288273\ttrain's ndcg@12: 0.373686\tvalidation's map@12: 0.236701\tvalidation's ndcg@12: 0.318622\n",
      "Early stopping, best iteration is:\n",
      "[211]\ttrain's map@12: 0.28295\ttrain's ndcg@12: 0.368286\tvalidation's map@12: 0.237121\tvalidation's ndcg@12: 0.318869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/../input/handmhelpers/modeling.py:272: FutureWarning: Parameter `output_class` was deprecated in version 25.06 and will be replaced with `is_classifier` in 25.08. Please use `is_classifier` in the future. For now, `output_class` parameter has been automatically converted to `is_classifier`.\n",
      "  model = ForestInference.load(model_path, model_type=\"lightgbm\", output_class=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC 0.7845\n",
      "Train score:  0.06832\n",
      "Eval AUC 0.7467\n",
      "Eval score: 0.03406\n",
      "\n",
      "\n",
      "age_bucket_flag         0\n",
      "last_weeks_flag         0\n",
      "pairs_flag              0\n",
      "recent_flag             1\n",
      "ca_count               11\n",
      "                     ... \n",
      "rebuy_count_ratio     398\n",
      "art_sales_channel     406\n",
      "trend_ratio_7_28      429\n",
      "cust_sales_channel    461\n",
      "last_1_days_count     516\n",
      "Length: 71, dtype: int32\n",
      "Finished cv of week 102 in 0:07:51.128386. Score: 0.03406\n",
      "\n",
      "preparing training modeling dfs for 102...\n",
      "candidates recall: 10.32% (24,561/238,074)\n",
      "candidates precision: 0.61% (24,561/4,033,310)\n",
      "preparing training modeling dfs for 101...\n",
      "candidates recall: 9.63% (24,570/255,172)\n",
      "candidates precision: 0.58% (24,570/4,270,526)\n",
      "preparing training modeling dfs for 100...\n",
      "candidates recall: 9.63% (22,224/230,825)\n",
      "candidates precision: 0.55% (22,224/4,039,298)\n",
      "preparing training modeling dfs for 99...\n",
      "candidates recall: 9.35% (22,171/237,160)\n",
      "candidates precision: 0.53% (22,171/4,209,718)\n",
      "preparing training modeling dfs for 98...\n",
      "candidates recall: 8.48% (22,010/259,512)\n",
      "candidates precision: 0.50% (22,010/4,395,378)\n",
      "concatenating all weeks together\n",
      "preparing evaluation modeling dfs...\n",
      "candidates recall: 9.97% (22,729/227,910)\n",
      "candidates precision: 0.59% (22,729/3,859,190)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Total groups: 83760, total data: 5958725\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.828221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12646\n",
      "[LightGBM] [Info] Number of data points in the train set: 5958725, number of used features: 71\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Total groups: 16721, total data: 1124998\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[10]\ttrain's map@12: 0.235113\ttrain's ndcg@12: 0.314897\tvalidation's map@12: 0.230969\tvalidation's ndcg@12: 0.308478\n",
      "[20]\ttrain's map@12: 0.240105\ttrain's ndcg@12: 0.320909\tvalidation's map@12: 0.234441\tvalidation's ndcg@12: 0.313366\n",
      "[30]\ttrain's map@12: 0.244029\ttrain's ndcg@12: 0.325571\tvalidation's map@12: 0.237293\tvalidation's ndcg@12: 0.316925\n",
      "[40]\ttrain's map@12: 0.246821\ttrain's ndcg@12: 0.328957\tvalidation's map@12: 0.238583\tvalidation's ndcg@12: 0.318209\n",
      "[50]\ttrain's map@12: 0.249695\ttrain's ndcg@12: 0.332331\tvalidation's map@12: 0.239663\tvalidation's ndcg@12: 0.319885\n",
      "[60]\ttrain's map@12: 0.25279\ttrain's ndcg@12: 0.335916\tvalidation's map@12: 0.241163\tvalidation's ndcg@12: 0.321574\n",
      "[70]\ttrain's map@12: 0.255166\ttrain's ndcg@12: 0.338574\tvalidation's map@12: 0.242418\tvalidation's ndcg@12: 0.323276\n",
      "[80]\ttrain's map@12: 0.257866\ttrain's ndcg@12: 0.341762\tvalidation's map@12: 0.243381\tvalidation's ndcg@12: 0.324536\n",
      "[90]\ttrain's map@12: 0.260201\ttrain's ndcg@12: 0.344339\tvalidation's map@12: 0.244197\tvalidation's ndcg@12: 0.325261\n",
      "[100]\ttrain's map@12: 0.262578\ttrain's ndcg@12: 0.346869\tvalidation's map@12: 0.245006\tvalidation's ndcg@12: 0.326152\n",
      "[110]\ttrain's map@12: 0.264663\ttrain's ndcg@12: 0.349259\tvalidation's map@12: 0.245966\tvalidation's ndcg@12: 0.326922\n",
      "[120]\ttrain's map@12: 0.266638\ttrain's ndcg@12: 0.351562\tvalidation's map@12: 0.246375\tvalidation's ndcg@12: 0.327343\n",
      "[130]\ttrain's map@12: 0.268506\ttrain's ndcg@12: 0.353538\tvalidation's map@12: 0.246761\tvalidation's ndcg@12: 0.327916\n",
      "[140]\ttrain's map@12: 0.270609\ttrain's ndcg@12: 0.355674\tvalidation's map@12: 0.246462\tvalidation's ndcg@12: 0.328036\n",
      "[150]\ttrain's map@12: 0.272835\ttrain's ndcg@12: 0.357994\tvalidation's map@12: 0.247156\tvalidation's ndcg@12: 0.328514\n",
      "[160]\ttrain's map@12: 0.274831\ttrain's ndcg@12: 0.359944\tvalidation's map@12: 0.246923\tvalidation's ndcg@12: 0.328262\n",
      "[170]\ttrain's map@12: 0.276435\ttrain's ndcg@12: 0.361761\tvalidation's map@12: 0.24741\tvalidation's ndcg@12: 0.328667\n",
      "[180]\ttrain's map@12: 0.278117\ttrain's ndcg@12: 0.363473\tvalidation's map@12: 0.247114\tvalidation's ndcg@12: 0.328463\n",
      "[190]\ttrain's map@12: 0.280104\ttrain's ndcg@12: 0.365493\tvalidation's map@12: 0.246963\tvalidation's ndcg@12: 0.328347\n",
      "[200]\ttrain's map@12: 0.281921\ttrain's ndcg@12: 0.367371\tvalidation's map@12: 0.246974\tvalidation's ndcg@12: 0.328258\n",
      "Early stopping, best iteration is:\n",
      "[176]\ttrain's map@12: 0.277662\ttrain's ndcg@12: 0.363\tvalidation's map@12: 0.247383\tvalidation's ndcg@12: 0.328985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/../input/handmhelpers/modeling.py:272: FutureWarning: Parameter `output_class` was deprecated in version 25.06 and will be replaced with `is_classifier` in 25.08. Please use `is_classifier` in the future. For now, `output_class` parameter has been automatically converted to `is_classifier`.\n",
      "  model = ForestInference.load(model_path, model_type=\"lightgbm\", output_class=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC 0.7824\n",
      "Train score:  0.06976\n",
      "Eval AUC 0.7575\n",
      "Eval score: 0.03419\n",
      "\n",
      "\n",
      "last_weeks_flag             0\n",
      "pairs_flag                  0\n",
      "recent_flag                 0\n",
      "age_bucket_flag             1\n",
      "pair_article_max_price     15\n",
      "                         ... \n",
      "cust_sales_channel        370\n",
      "trend_ratio_7_28          374\n",
      "rebuy_count_ratio         377\n",
      "newness_days              390\n",
      "last_1_days_count         491\n",
      "Length: 71, dtype: int32\n",
      "Finished cv of week 103 in 0:07:00.376217. Score: 0.03419\n",
      "\n",
      "preparing training modeling dfs for 103...\n",
      "candidates recall: 9.97% (22,729/227,910)\n",
      "candidates precision: 0.59% (22,729/3,859,190)\n",
      "preparing training modeling dfs for 102...\n",
      "candidates recall: 10.32% (24,561/238,074)\n",
      "candidates precision: 0.61% (24,561/4,033,310)\n",
      "preparing training modeling dfs for 101...\n",
      "candidates recall: 9.63% (24,570/255,172)\n",
      "candidates precision: 0.58% (24,570/4,270,526)\n",
      "preparing training modeling dfs for 100...\n",
      "candidates recall: 9.63% (22,224/230,825)\n",
      "candidates precision: 0.55% (22,224/4,039,298)\n",
      "preparing training modeling dfs for 99...\n",
      "candidates recall: 9.35% (22,171/237,160)\n",
      "candidates precision: 0.53% (22,171/4,209,718)\n",
      "concatenating all weeks together\n",
      "preparing evaluation modeling dfs...\n",
      "candidates recall: 10.92% (23,330/213,728)\n",
      "candidates precision: 0.66% (23,330/3,544,139)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Total groups: 84651, total data: 5865492\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.811868 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12663\n",
      "[LightGBM] [Info] Number of data points in the train set: 5865492, number of used features: 71\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Total groups: 16619, total data: 1076216\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[10]\ttrain's map@12: 0.238727\ttrain's ndcg@12: 0.319433\tvalidation's map@12: 0.223412\tvalidation's ndcg@12: 0.302536\n",
      "[20]\ttrain's map@12: 0.244432\ttrain's ndcg@12: 0.326058\tvalidation's map@12: 0.227085\tvalidation's ndcg@12: 0.306649\n",
      "[30]\ttrain's map@12: 0.248518\ttrain's ndcg@12: 0.330667\tvalidation's map@12: 0.230126\tvalidation's ndcg@12: 0.309946\n",
      "[40]\ttrain's map@12: 0.25177\ttrain's ndcg@12: 0.334686\tvalidation's map@12: 0.232256\tvalidation's ndcg@12: 0.312312\n",
      "[50]\ttrain's map@12: 0.254637\ttrain's ndcg@12: 0.337842\tvalidation's map@12: 0.232399\tvalidation's ndcg@12: 0.313118\n",
      "[60]\ttrain's map@12: 0.25708\ttrain's ndcg@12: 0.340746\tvalidation's map@12: 0.232712\tvalidation's ndcg@12: 0.314263\n",
      "[70]\ttrain's map@12: 0.259788\ttrain's ndcg@12: 0.343985\tvalidation's map@12: 0.233691\tvalidation's ndcg@12: 0.315462\n",
      "[80]\ttrain's map@12: 0.262335\ttrain's ndcg@12: 0.346956\tvalidation's map@12: 0.234132\tvalidation's ndcg@12: 0.315973\n",
      "[90]\ttrain's map@12: 0.26413\ttrain's ndcg@12: 0.349072\tvalidation's map@12: 0.235145\tvalidation's ndcg@12: 0.317183\n",
      "[100]\ttrain's map@12: 0.266198\ttrain's ndcg@12: 0.351348\tvalidation's map@12: 0.235704\tvalidation's ndcg@12: 0.318152\n",
      "[110]\ttrain's map@12: 0.268267\ttrain's ndcg@12: 0.353626\tvalidation's map@12: 0.235824\tvalidation's ndcg@12: 0.318659\n",
      "[120]\ttrain's map@12: 0.27008\ttrain's ndcg@12: 0.355673\tvalidation's map@12: 0.236194\tvalidation's ndcg@12: 0.319095\n",
      "[130]\ttrain's map@12: 0.272177\ttrain's ndcg@12: 0.357973\tvalidation's map@12: 0.236534\tvalidation's ndcg@12: 0.319213\n",
      "[140]\ttrain's map@12: 0.274169\ttrain's ndcg@12: 0.360043\tvalidation's map@12: 0.236484\tvalidation's ndcg@12: 0.319171\n",
      "[150]\ttrain's map@12: 0.276077\ttrain's ndcg@12: 0.362155\tvalidation's map@12: 0.236467\tvalidation's ndcg@12: 0.319198\n",
      "[160]\ttrain's map@12: 0.278044\ttrain's ndcg@12: 0.364184\tvalidation's map@12: 0.236832\tvalidation's ndcg@12: 0.319729\n",
      "[170]\ttrain's map@12: 0.279847\ttrain's ndcg@12: 0.366034\tvalidation's map@12: 0.236774\tvalidation's ndcg@12: 0.31956\n",
      "[180]\ttrain's map@12: 0.281813\ttrain's ndcg@12: 0.367969\tvalidation's map@12: 0.236899\tvalidation's ndcg@12: 0.319748\n",
      "[190]\ttrain's map@12: 0.283499\ttrain's ndcg@12: 0.369772\tvalidation's map@12: 0.237003\tvalidation's ndcg@12: 0.319849\n",
      "[200]\ttrain's map@12: 0.285513\ttrain's ndcg@12: 0.371833\tvalidation's map@12: 0.236885\tvalidation's ndcg@12: 0.319942\n",
      "[210]\ttrain's map@12: 0.287303\ttrain's ndcg@12: 0.373584\tvalidation's map@12: 0.2369\tvalidation's ndcg@12: 0.320026\n",
      "Early stopping, best iteration is:\n",
      "[188]\ttrain's map@12: 0.283224\ttrain's ndcg@12: 0.369421\tvalidation's map@12: 0.237268\tvalidation's ndcg@12: 0.320047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/../input/handmhelpers/modeling.py:272: FutureWarning: Parameter `output_class` was deprecated in version 25.06 and will be replaced with `is_classifier` in 25.08. Please use `is_classifier` in the future. For now, `output_class` parameter has been automatically converted to `is_classifier`.\n",
      "  model = ForestInference.load(model_path, model_type=\"lightgbm\", output_class=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC 0.7844\n",
      "Train score:  0.07276\n",
      "Eval AUC 0.7459\n",
      "Eval score: 0.03548\n",
      "\n",
      "\n",
      "last_weeks_flag             0\n",
      "pairs_flag                  0\n",
      "recent_flag                 0\n",
      "age_bucket_flag             1\n",
      "pair_article_max_price     15\n",
      "                         ... \n",
      "rebuy_count_ratio         362\n",
      "art_sales_channel         370\n",
      "trend_ratio_7_28          378\n",
      "newness_days              438\n",
      "last_1_days_count         451\n",
      "Length: 71, dtype: int32\n",
      "Finished cv of week 104 in 0:07:09.521138. Score: 0.03548\n",
      "\n",
      "Finished all 3 cvs in 0:22:01.025739. Average cv score: 0.03458\n",
      "CPU times: user 38min 20s, sys: 59.1 s, total: 39min 19s\n",
      "Wall time: 22min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Chạy cross-validation cho các tuần 102–104 (đa tuần để ổn định hơn so với 1 tuần)\n",
    "cv_weeks = [102, 103, 104]\n",
    "results = h_modeling.run_all_cvs(\n",
    "    t, c, a, cand_features_func, scoring_func,\n",
    "    cv_weeks=cv_weeks, **cv_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T02:21:38.462652Z",
     "iopub.status.busy": "2025-12-29T02:21:38.462278Z",
     "iopub.status.idle": "2025-12-29T02:21:38.467311Z",
     "shell.execute_reply": "2025-12-29T02:21:38.466553Z",
     "shell.execute_reply.started": "2025-12-29T02:21:38.462630Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from cuml.fil import ForestInference as _FI\n",
    "\n",
    "_real_load = _FI.load\n",
    "\n",
    "def _load_compat(*args, output_class=None, is_classifier=None, **kwargs):\n",
    "    # helper cũ truyền output_class -> map sang is_classifier\n",
    "    if is_classifier is None and output_class is not None:\n",
    "        is_classifier = output_class\n",
    "    return _real_load(*args, is_classifier=is_classifier, **kwargs)\n",
    "\n",
    "_FI.load = staticmethod(_load_compat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T02:21:38.468511Z",
     "iopub.status.busy": "2025-12-29T02:21:38.468216Z",
     "iopub.status.idle": "2025-12-29T02:21:38.483539Z",
     "shell.execute_reply": "2025-12-29T02:21:38.482913Z",
     "shell.execute_reply.started": "2025-12-29T02:21:38.468462Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=r\".*Parameter `output_class` was deprecated.*\",\n",
    "    category=FutureWarning,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T02:36:55.153451Z",
     "iopub.status.busy": "2025-12-29T02:36:55.152730Z",
     "iopub.status.idle": "2025-12-29T02:36:55.161005Z",
     "shell.execute_reply": "2025-12-29T02:36:55.160286Z",
     "shell.execute_reply.started": "2025-12-29T02:36:55.153418Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import handmhelpers.modeling as h_modeling\n",
    "\n",
    "def full_sub_predict_run_small_batches(t, c, a, cand_features_func, batch_splits=8, **kwargs):\n",
    "    # Chia khách hàng thành nhiều batch nhỏ để tránh OOM khi tạo feature/predict\n",
    "    customer_batches = []\n",
    "    n = len(c)\n",
    "    for i in range(batch_splits):\n",
    "        start = i * n // batch_splits\n",
    "        end = (i + 1) * n // batch_splits\n",
    "        customer_batches.append(c[start:end][\"customer_id\"].to_pandas().to_list())\n",
    "\n",
    "    batch_preds = []\n",
    "    for idx, customer_batch in enumerate(customer_batches):\n",
    "        print(f\"generating candidates/features for batch #{idx+1} of {len(customer_batches)}\")\n",
    "        sub_ids_df, sub_X = h_modeling.prepare_prediction_dfs(\n",
    "            t, c, a, cand_features_func, customer_batch=customer_batch, **kwargs\n",
    "        )\n",
    "        print(f\"candidate/features shape of batch: ({sub_X.shape[0]:,}, {sub_X.shape[1]})\")\n",
    "\n",
    "        # Ensemble các model trong prediction_models, trung bình điểm\n",
    "        model_paths = kwargs.get(\"prediction_models\")\n",
    "        model_nums = len(model_paths)\n",
    "        first_model = h_modeling.ForestInference.load(model_paths[0], model_type=\"lightgbm\", output_class=False)\n",
    "        sub_pred = h_modeling.pred_in_batches(first_model, sub_X) / model_nums\n",
    "        del first_model\n",
    "\n",
    "        for mp in model_paths[1:]:\n",
    "            m = h_modeling.ForestInference.load(mp, model_type=\"lightgbm\", output_class=False)\n",
    "            sub_pred += h_modeling.pred_in_batches(m, sub_X) / model_nums\n",
    "            del m\n",
    "\n",
    "        batch_preds.append(h_modeling.create_predictions(sub_ids_df, sub_pred))\n",
    "        del sub_ids_df, sub_X, sub_pred\n",
    "\n",
    "    return cudf.concat(batch_preds)\n",
    "\n",
    "# Ghi đè hàm predict gốc để dùng bản chia batch nhỏ\n",
    "h_modeling.full_sub_predict_run = full_sub_predict_run_small_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T02:38:37.054458Z",
     "iopub.status.busy": "2025-12-29T02:38:37.053906Z",
     "iopub.status.idle": "2025-12-29T02:53:17.212091Z",
     "shell.execute_reply": "2025-12-29T02:53:17.211281Z",
     "shell.execute_reply.started": "2025-12-29T02:38:37.054428Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing training modeling dfs for 104...\n",
      "preparing training modeling dfs for 103...\n",
      "preparing training modeling dfs for 102...\n",
      "preparing training modeling dfs for 101...\n",
      "preparing training modeling dfs for 100...\n",
      "concatenating all weeks together\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Total groups: 86093, total data: 5761241\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.873492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12668\n",
      "[LightGBM] [Info] Number of data points in the train set: 5761241, number of used features: 71\n",
      "[10]\ttrain's map@12: 0.238545\ttrain's ndcg@12: 0.319674\n",
      "[20]\ttrain's map@12: 0.242711\ttrain's ndcg@12: 0.324727\n",
      "[30]\ttrain's map@12: 0.247015\ttrain's ndcg@12: 0.329551\n",
      "[40]\ttrain's map@12: 0.250503\ttrain's ndcg@12: 0.333571\n",
      "[50]\ttrain's map@12: 0.253272\ttrain's ndcg@12: 0.336888\n",
      "[60]\ttrain's map@12: 0.255654\ttrain's ndcg@12: 0.339579\n",
      "[70]\ttrain's map@12: 0.258208\ttrain's ndcg@12: 0.342515\n",
      "[80]\ttrain's map@12: 0.260315\ttrain's ndcg@12: 0.344837\n",
      "[90]\ttrain's map@12: 0.262604\ttrain's ndcg@12: 0.347416\n",
      "[100]\ttrain's map@12: 0.264539\ttrain's ndcg@12: 0.349667\n",
      "[110]\ttrain's map@12: 0.266571\ttrain's ndcg@12: 0.351976\n",
      "[120]\ttrain's map@12: 0.26874\ttrain's ndcg@12: 0.354248\n",
      "[130]\ttrain's map@12: 0.271084\ttrain's ndcg@12: 0.356821\n",
      "[140]\ttrain's map@12: 0.272952\ttrain's ndcg@12: 0.358845\n",
      "[150]\ttrain's map@12: 0.274853\ttrain's ndcg@12: 0.360835\n",
      "[160]\ttrain's map@12: 0.276842\ttrain's ndcg@12: 0.362978\n",
      "[170]\ttrain's map@12: 0.278891\ttrain's ndcg@12: 0.365038\n",
      "[180]\ttrain's map@12: 0.28088\ttrain's ndcg@12: 0.366973\n",
      "[190]\ttrain's map@12: 0.282766\ttrain's ndcg@12: 0.36901\n",
      "[200]\ttrain's map@12: 0.284693\ttrain's ndcg@12: 0.370873\n",
      "[210]\ttrain's map@12: 0.286274\ttrain's ndcg@12: 0.372538\n",
      "[220]\ttrain's map@12: 0.288126\ttrain's ndcg@12: 0.374441\n",
      "[230]\ttrain's map@12: 0.289742\ttrain's ndcg@12: 0.376199\n",
      "[240]\ttrain's map@12: 0.291477\ttrain's ndcg@12: 0.37783\n",
      "[250]\ttrain's map@12: 0.293127\ttrain's ndcg@12: 0.379602\n",
      "[260]\ttrain's map@12: 0.294838\ttrain's ndcg@12: 0.381289\n",
      "[270]\ttrain's map@12: 0.296451\ttrain's ndcg@12: 0.383011\n",
      "[280]\ttrain's map@12: 0.297981\ttrain's ndcg@12: 0.384554\n",
      "[290]\ttrain's map@12: 0.299623\ttrain's ndcg@12: 0.386109\n",
      "[300]\ttrain's map@12: 0.301066\ttrain's ndcg@12: 0.387519\n",
      "[310]\ttrain's map@12: 0.302417\ttrain's ndcg@12: 0.389018\n",
      "[320]\ttrain's map@12: 0.304014\ttrain's ndcg@12: 0.390775\n",
      "[330]\ttrain's map@12: 0.305272\ttrain's ndcg@12: 0.392072\n",
      "[340]\ttrain's map@12: 0.30652\ttrain's ndcg@12: 0.393461\n",
      "[350]\ttrain's map@12: 0.30806\ttrain's ndcg@12: 0.395059\n",
      "[360]\ttrain's map@12: 0.309688\ttrain's ndcg@12: 0.396547\n",
      "[370]\ttrain's map@12: 0.310919\ttrain's ndcg@12: 0.397782\n",
      "[380]\ttrain's map@12: 0.312391\ttrain's ndcg@12: 0.39921\n",
      "[390]\ttrain's map@12: 0.313742\ttrain's ndcg@12: 0.400725\n",
      "[400]\ttrain's map@12: 0.314881\ttrain's ndcg@12: 0.401818\n",
      "[410]\ttrain's map@12: 0.316361\ttrain's ndcg@12: 0.403317\n",
      "[420]\ttrain's map@12: 0.31773\ttrain's ndcg@12: 0.404784\n",
      "[430]\ttrain's map@12: 0.319397\ttrain's ndcg@12: 0.40646\n",
      "[440]\ttrain's map@12: 0.320876\ttrain's ndcg@12: 0.40798\n",
      "[450]\ttrain's map@12: 0.322336\ttrain's ndcg@12: 0.409443\n",
      "[460]\ttrain's map@12: 0.32345\ttrain's ndcg@12: 0.410664\n",
      "[470]\ttrain's map@12: 0.324934\ttrain's ndcg@12: 0.412186\n",
      "[480]\ttrain's map@12: 0.326316\ttrain's ndcg@12: 0.413586\n",
      "[490]\ttrain's map@12: 0.32753\ttrain's ndcg@12: 0.414944\n",
      "[500]\ttrain's map@12: 0.328788\ttrain's ndcg@12: 0.41628\n",
      "Train AUC 0.7973\n",
      "Train score:  0.07864\n",
      "generating candidates/features for batch #1 of 8\n",
      "candidate/features shape of batch: (7,292,186, 71)\n",
      "generating candidates/features for batch #2 of 8\n",
      "candidate/features shape of batch: (7,263,256, 71)\n",
      "generating candidates/features for batch #3 of 8\n",
      "candidate/features shape of batch: (7,275,532, 71)\n",
      "generating candidates/features for batch #4 of 8\n",
      "candidate/features shape of batch: (7,277,475, 71)\n",
      "generating candidates/features for batch #5 of 8\n",
      "candidate/features shape of batch: (7,283,666, 71)\n",
      "generating candidates/features for batch #6 of 8\n",
      "candidate/features shape of batch: (7,274,857, 71)\n",
      "generating candidates/features for batch #7 of 8\n",
      "candidate/features shape of batch: (7,267,793, 71)\n",
      "generating candidates/features for batch #8 of 8\n",
      "candidate/features shape of batch: (7,264,833, 71)\n",
      "CPU times: user 23min 35s, sys: 1min 9s, total: 24min 45s\n",
      "Wall time: 14min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gc.collect()\n",
    "# Train full dữ liệu submit và lưu model theo sub_params\n",
    "h_modeling.full_sub_train_run(t, c, a, cand_features_func, scoring_func, **sub_params)\n",
    "# Predict theo batch nhỏ (batch_splits=8) để tránh OOM, dùng ensemble model_104/model_105\n",
    "predictions = h_modeling.full_sub_predict_run(\n",
    "    t, c, a, cand_features_func, batch_splits=8, **sub_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T02:53:54.839924Z",
     "iopub.status.busy": "2025-12-29T02:53:54.839136Z",
     "iopub.status.idle": "2025-12-29T02:54:30.527006Z",
     "shell.execute_reply": "2025-12-29T02:54:30.526317Z",
     "shell.execute_reply.started": "2025-12-29T02:53:54.839891Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "      <td>0568601043 0779781015 0568601044 0858856005 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n",
       "      <td>0863583001 0918522001 0448509014 0915529003 09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>0794321007 0794321008 0805000001 0918522001 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...</td>\n",
       "      <td>0861803009 0852584001 0730683050 0928206001 09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...</td>\n",
       "      <td>0730683050 0918522001 0791587021 0928206001 09...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_id  \\\n",
       "0  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...   \n",
       "1  0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...   \n",
       "2  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   \n",
       "3  00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...   \n",
       "4  00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...   \n",
       "\n",
       "                                          prediction  \n",
       "0  0568601043 0779781015 0568601044 0858856005 07...  \n",
       "1  0863583001 0918522001 0448509014 0915529003 09...  \n",
       "2  0794321007 0794321008 0805000001 0918522001 07...  \n",
       "3  0861803009 0852584001 0730683050 0928206001 09...  \n",
       "4  0730683050 0918522001 0791587021 0928206001 09...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1371980, 2)\n"
     ]
    }
   ],
   "source": [
    "sub = h_sub.create_sub(c[\"customer_id\"], predictions, index_to_id_dict_path)\n",
    "sub.to_csv('dev_submission.csv', index=False)\n",
    "\n",
    "display(sub.head())\n",
    "print(sub.shape)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 3103714,
     "sourceId": 31254,
     "sourceType": "competition"
    },
    {
     "datasetId": 9140518,
     "sourceId": 14318670,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
